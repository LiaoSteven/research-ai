#!/usr/bin/env python3
"""
é‡‡é›† AI ç”Ÿæˆå†…å®¹è§†é¢‘çš„è¯„è®º

ä¸“é—¨æœç´¢å’Œé‡‡é›† AI ç›¸å…³è§†é¢‘ï¼ˆAI generated, AI art, AI music ç­‰ï¼‰çš„è¯„è®º

ä½¿ç”¨æ–¹æ³•ï¼š
    python collect_ai_videos.py --max-comments 1000
"""

import sys
from pathlib import Path
import argparse
import os
import json
import time
from datetime import datetime

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "src" / "main" / "python"))

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# å¯¼å…¥æ¨¡å—
import services.youtube_collector as yt_module
YouTubeCollector = yt_module.YouTubeCollector


class AIVideoCollector:
    """ä¸“é—¨é‡‡é›† AI ç›¸å…³è§†é¢‘è¯„è®º"""

    # AI ç›¸å…³æœç´¢å…³é”®è¯
    AI_KEYWORDS = [
        'AI generated',
        'AI art',
        'AI music',
        'AI animation',
        'AI video',
        'artificial intelligence',
        'midjourney',
        'stable diffusion',
        'dall-e',
        'chatgpt',
        'AI created',
        'made with AI',
        'AI assisted',
        'generative AI',
        'AI shorts',
        'AI content'
    ]

    # é AI å…³é”®è¯ï¼ˆç”¨äºå¯¹ç…§ç»„ï¼‰
    NON_AI_KEYWORDS = [
        'handmade',
        'hand drawn',
        'traditional art',
        'real footage',
        'live action',
        'filmed',
        'recorded',
        'original content',
        'human made'
    ]

    def __init__(self, api_key: str):
        """åˆå§‹åŒ–é‡‡é›†å™¨"""
        self.collector = YouTubeCollector(api_key=api_key)
        self.youtube = self.collector.youtube

    def search_ai_videos(
        self,
        max_results: int = 50,
        keywords: list = None,
        region: str = 'US'
    ) -> list:
        """
        æœç´¢ AI ç›¸å…³è§†é¢‘

        Args:
            max_results: æœ€å¤šè¿”å›å¤šå°‘ä¸ªè§†é¢‘
            keywords: æœç´¢å…³é”®è¯åˆ—è¡¨
            region: åœ°åŒºä»£ç 

        Returns:
            è§†é¢‘ ID åˆ—è¡¨
        """
        if keywords is None:
            keywords = self.AI_KEYWORDS

        video_ids = []
        found_videos = set()

        print(f"\nğŸ¤– æœç´¢ AI ç›¸å…³è§†é¢‘...")
        print(f"   å…³é”®è¯æ•°é‡: {len(keywords)}")
        print(f"   åœ°åŒº: {region}")

        for keyword in keywords:
            if len(video_ids) >= max_results:
                break

            print(f"\n   æœç´¢å…³é”®è¯: '{keyword}'")

            try:
                # æ„å»ºæœç´¢å‚æ•°
                search_params = {
                    'part': 'id,snippet',
                    'type': 'video',
                    'q': f'{keyword} shorts',
                    'videoDuration': 'short',  # çŸ­è§†é¢‘
                    'maxResults': 10,
                    'order': 'relevance',
                    'regionCode': region,
                    'relevanceLanguage': 'en'  # è‹±æ–‡å†…å®¹
                }

                request = self.youtube.search().list(**search_params)
                response = request.execute()

                for item in response.get('items', []):
                    if 'videoId' in item['id']:
                        video_id = item['id']['videoId']
                        if video_id not in found_videos:
                            found_videos.add(video_id)
                            video_ids.append(video_id)
                            print(f"      âœ“ æ‰¾åˆ°: {video_id}")

                time.sleep(1)  # é€Ÿç‡é™åˆ¶

            except Exception as e:
                print(f"      âœ— æœç´¢é”™è¯¯: {e}")
                continue

        print(f"\nâœ… å…±æ‰¾åˆ° {len(video_ids)} ä¸ª AI ç›¸å…³è§†é¢‘")
        return video_ids[:max_results]

    def verify_ai_content(self, video_id: str) -> dict:
        """
        éªŒè¯è§†é¢‘æ˜¯å¦çœŸçš„æ˜¯ AI å†…å®¹

        é€šè¿‡æ ‡é¢˜ã€æè¿°ã€æ ‡ç­¾æ¥åˆ¤æ–­

        Args:
            video_id: è§†é¢‘ ID

        Returns:
            åŒ…å«éªŒè¯ç»“æœçš„å­—å…¸
        """
        try:
            video_info = self.collector.get_video_info(video_id)

            # æ£€æŸ¥æ ‡é¢˜å’Œæè¿°ä¸­çš„ AI å…³é”®è¯
            title_lower = video_info['title'].lower()
            desc_lower = video_info.get('description', '').lower()
            tags = video_info.get('tags', [])

            ai_indicators = 0
            found_keywords = []

            # æ£€æŸ¥æ ‡é¢˜
            for keyword in self.AI_KEYWORDS:
                if keyword.lower() in title_lower:
                    ai_indicators += 2  # æ ‡é¢˜æƒé‡æ›´é«˜
                    found_keywords.append(f"title:{keyword}")

            # æ£€æŸ¥æè¿°
            for keyword in self.AI_KEYWORDS:
                if keyword.lower() in desc_lower:
                    ai_indicators += 1
                    found_keywords.append(f"desc:{keyword}")

            # æ£€æŸ¥æ ‡ç­¾
            for tag in tags:
                if any(kw.lower() in tag.lower() for kw in ['ai', 'artificial', 'generated']):
                    ai_indicators += 1
                    found_keywords.append(f"tag:{tag}")

            is_likely_ai = ai_indicators >= 2

            return {
                'video_id': video_id,
                'is_likely_ai': is_likely_ai,
                'confidence': min(ai_indicators / 5, 1.0),  # 0-1 ç½®ä¿¡åº¦
                'ai_indicators': ai_indicators,
                'found_keywords': found_keywords,
                'title': video_info['title']
            }

        except Exception as e:
            print(f"   âš ï¸  éªŒè¯å¤±è´¥: {e}")
            return {
                'video_id': video_id,
                'is_likely_ai': False,
                'confidence': 0.0,
                'ai_indicators': 0,
                'found_keywords': [],
                'error': str(e)
            }


def main():
    parser = argparse.ArgumentParser(description='é‡‡é›† AI ç”Ÿæˆå†…å®¹è§†é¢‘è¯„è®º')
    parser.add_argument('--max-comments', type=int, default=1000,
                       help='æ€»å…±é‡‡é›†å¤šå°‘æ¡è¯„è®ºï¼ˆé»˜è®¤ 1000ï¼‰')
    parser.add_argument('--per-video', type=int, default=50,
                       help='æ¯ä¸ªè§†é¢‘é‡‡é›†å¤šå°‘æ¡è¯„è®ºï¼ˆé»˜è®¤ 50ï¼‰')
    parser.add_argument('--region', type=str, default='US',
                       help='åœ°åŒºä»£ç ï¼ˆé»˜è®¤ USï¼‰')
    parser.add_argument('--type', type=str, default='ai',
                       choices=['ai', 'non_ai'],
                       help='é‡‡é›†ç±»å‹ï¼šai=AIç”Ÿæˆå†…å®¹ï¼Œnon_ai=éAIå†…å®¹')
    parser.add_argument('--verify', action='store_true',
                       help='éªŒè¯è§†é¢‘æ˜¯å¦çœŸçš„æ˜¯ AI å†…å®¹')

    args = parser.parse_args()

    print("\n" + "="*70)
    print(" AI è§†é¢‘è¯„è®ºé‡‡é›†å·¥å…·")
    print("="*70 + "\n")

    # æ£€æŸ¥ API key
    api_key = os.getenv('YOUTUBE_API_KEY')
    if not api_key:
        print("âŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° YouTube API å¯†é’¥")
        print("\nè¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® YOUTUBE_API_KEY")
        return 1

    # åˆå§‹åŒ–é‡‡é›†å™¨
    try:
        ai_collector = AIVideoCollector(api_key=api_key)
        print("âœ… YouTube API è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1

    # è®¡ç®—éœ€è¦å¤šå°‘ä¸ªè§†é¢‘
    videos_needed = (args.max_comments // args.per_video) + 1

    print(f"\nğŸ“Š é‡‡é›†å‚æ•°ï¼š")
    print(f"   ç›®æ ‡è¯„è®ºæ•°ï¼š{args.max_comments}")
    print(f"   æ¯è§†é¢‘è¯„è®ºï¼š{args.per_video}")
    print(f"   éœ€è¦è§†é¢‘æ•°ï¼šçº¦ {videos_needed}")
    print(f"   é‡‡é›†ç±»å‹ï¼š{args.type}")
    print(f"   åœ°åŒºä»£ç ï¼š{args.region}")
    print(f"   éªŒè¯æ¨¡å¼ï¼š{'å¼€å¯' if args.verify else 'å…³é—­'}")

    # é€‰æ‹©æœç´¢å…³é”®è¯
    if args.type == 'ai':
        keywords = ai_collector.AI_KEYWORDS
        label = 'ai_generated'
    else:
        keywords = ai_collector.NON_AI_KEYWORDS
        label = 'non_ai'

    # æœç´¢è§†é¢‘
    video_ids = ai_collector.search_ai_videos(
        max_results=videos_needed * 2,  # å¤šæœç´¢ä¸€äº›ï¼Œå› ä¸ºæœ‰äº›å¯èƒ½ä¸åˆæ ¼
        keywords=keywords,
        region=args.region
    )

    if not video_ids:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°è§†é¢‘")
        return 1

    # éªŒè¯è§†é¢‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    verified_videos = []
    if args.verify:
        print(f"\nğŸ” éªŒè¯è§†é¢‘å†…å®¹...")
        for video_id in video_ids:
            result = ai_collector.verify_ai_content(video_id)
            if result['is_likely_ai']:
                verified_videos.append(result)
                print(f"   âœ“ {result['video_id']}: {result['title'][:50]}...")
                print(f"      ç½®ä¿¡åº¦: {result['confidence']:.2f}, æŒ‡æ ‡: {result['ai_indicators']}")
            else:
                print(f"   âœ— {result['video_id']}: ä¸ç¡®å®šæ˜¯ AI å†…å®¹")

            if len(verified_videos) >= videos_needed:
                break

        video_ids = [v['video_id'] for v in verified_videos]
        print(f"\nâœ… éªŒè¯é€šè¿‡ {len(video_ids)} ä¸ªè§†é¢‘")

    if not video_ids:
        print("âŒ æ²¡æœ‰é€šè¿‡éªŒè¯çš„è§†é¢‘")
        return 1

    print(f"\nğŸ¬ å‡†å¤‡ä» {len(video_ids[:videos_needed])} ä¸ªè§†é¢‘ä¸­é‡‡é›†è¯„è®º...\n")

    # é‡‡é›†è¯„è®º
    all_comments = []
    video_info_list = []

    for idx, video_id in enumerate(video_ids[:videos_needed], 1):
        if len(all_comments) >= args.max_comments:
            print(f"\nâœ… å·²è¾¾åˆ°ç›®æ ‡è¯„è®ºæ•° {args.max_comments}ï¼Œåœæ­¢é‡‡é›†")
            break

        print(f"[{idx}/{min(len(video_ids), videos_needed)}] å¤„ç†è§†é¢‘: {video_id}")

        try:
            # è·å–è§†é¢‘ä¿¡æ¯
            video_info = ai_collector.collector.get_video_info(video_id)
            video_info['video_type'] = label
            video_info['region'] = args.region

            title = video_info['title'][:40] + "..." if len(video_info['title']) > 40 else video_info['title']
            print(f"  æ ‡é¢˜: {title}")
            print(f"  è¯„è®ºæ•°: {video_info['comment_count']}")

            video_info_list.append(video_info)

            # è·å–è¯„è®º
            comments = ai_collector.collector.get_video_comments(
                video_id,
                max_comments=args.per_video,
                include_replies=True
            )

            # æ·»åŠ æ ‡ç­¾
            for comment in comments:
                comment['video_type'] = label
                comment['region'] = args.region

            all_comments.extend(comments)
            print(f"  âœ“ é‡‡é›†äº† {len(comments)} æ¡è¯„è®ºï¼ˆæ€»è®¡: {len(all_comments)}ï¼‰")

            time.sleep(1)

        except Exception as e:
            print(f"  âœ— é‡‡é›†å¤±è´¥: {e}")
            continue

    # ä¿å­˜ç»“æœ
    if all_comments:
        output_dir = Path('data/raw')
        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        comments_file = output_dir / f'comments_{label}_{timestamp}.json'
        videos_file = output_dir / f'videos_{label}_{timestamp}.json'

        with open(comments_file, 'w', encoding='utf-8') as f:
            json.dump(all_comments, f, ensure_ascii=False, indent=2)

        with open(videos_file, 'w', encoding='utf-8') as f:
            json.dump(video_info_list, f, ensure_ascii=False, indent=2)

        print("\n" + "="*70)
        print(" é‡‡é›†å®Œæˆï¼")
        print("="*70)
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯ï¼š")
        print(f"  æ€»è¯„è®ºæ•°ï¼š{len(all_comments)}")
        print(f"  å¤„ç†è§†é¢‘ï¼š{len(video_info_list)}")
        print(f"  ç±»å‹æ ‡ç­¾ï¼š{label}")
        print(f"  åœ°åŒºï¼š{args.region}")

        print(f"\nğŸ’¾ æ–‡ä»¶ä¿å­˜ä½ç½®ï¼š")
        print(f"  è¯„è®ºæ•°æ®ï¼š{comments_file}")
        print(f"  è§†é¢‘ä¿¡æ¯ï¼š{videos_file}")

        print(f"\nğŸ“ è¯„è®ºæ ·æœ¬ï¼ˆå‰ 3 æ¡ï¼‰ï¼š")
        for i, comment in enumerate(all_comments[:3], 1):
            text = comment['text'][:60] + "..." if len(comment['text']) > 60 else comment['text']
            print(f"  {i}. {comment['author']}: {text}")

        print("\nâœ¨ ä¸‹ä¸€æ­¥ï¼š")
        print(f"  1. é‡‡é›†å¯¹ç…§ç»„ï¼š")
        if args.type == 'ai':
            print(f"     python collect_ai_videos.py --type non_ai --max-comments {args.max_comments}")
        else:
            print(f"     python collect_ai_videos.py --type ai --max-comments {args.max_comments}")
        print(f"  2. é¢„å¤„ç†æ•°æ®ï¼špython scripts/preprocess_data.py --input {comments_file}")
        print(f"  3. å¯¹æ¯”åˆ†æï¼šæ¯”è¾ƒ ai_generated vs non_ai çš„æƒ…æ„Ÿå’Œä¸»é¢˜å·®å¼‚")

        print()
        return 0
    else:
        print("\nâŒ æ²¡æœ‰é‡‡é›†åˆ°ä»»ä½•è¯„è®º")
        return 1


if __name__ == '__main__':
    sys.exit(main())
