#!/usr/bin/env python3
"""
åˆ†æé‡‡é›†çš„æ•°æ®å¹¶ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š

ç”Ÿæˆå†…å®¹ï¼š
1. AIå æ¯”æ¼”å˜è¶‹åŠ¿å›¾
2. AI vs éAI äº’åŠ¨æŒ‡æ ‡å¯¹æ¯”
3. AIæ£€æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ
4. è¯„è®ºé•¿åº¦å¯¹æ¯”
5. ç»¼åˆç ”ç©¶æŠ¥å‘Š
"""

import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from datetime import datetime
from pathlib import Path
import sys

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Arial', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

def load_data(data_file):
    """åŠ è½½æ•°æ®"""
    print(f"åŠ è½½æ•°æ®: {data_file}")
    with open(data_file, 'r', encoding='utf-8') as f:
        comments = json.load(f)
    return pd.DataFrame(comments)

def analyze_ai_ratio_evolution(df, output_dir):
    """åˆ†æAIå æ¯”æ¼”å˜"""
    print("\n1ï¸âƒ£ åˆ†æAIå æ¯”æ¼”å˜...")

    quarter_stats = df.groupby('quarter').agg({
        'video_type': lambda x: (x == 'ai_generated').sum(),
        'comment_id': 'count'
    }).rename(columns={'video_type': 'ai_count', 'comment_id': 'total'})

    quarter_stats['ai_ratio'] = (quarter_stats['ai_count'] / quarter_stats['total'] * 100).round(1)
    quarter_stats = quarter_stats.sort_index()

    # ç»˜å›¾
    fig, ax = plt.subplots(figsize=(12, 6))

    quarters = quarter_stats.index.tolist()
    ai_ratios = quarter_stats['ai_ratio'].values

    ax.plot(quarters, ai_ratios, marker='o', linewidth=2, markersize=8,
            color='#FF6B6B', label='AI Content Ratio')
    ax.fill_between(range(len(quarters)), ai_ratios, alpha=0.3, color='#FF6B6B')

    ax.set_xlabel('Quarter', fontsize=12, fontweight='bold')
    ax.set_ylabel('AI Content Ratio (%)', fontsize=12, fontweight='bold')
    ax.set_title('AI Content Ratio Evolution (2022-2025)', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend()

    plt.xticks(rotation=45)
    plt.tight_layout()

    output_file = output_dir / 'ai_ratio_evolution.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ“ ä¿å­˜å›¾è¡¨: {output_file}")
    plt.close()

    return quarter_stats

def analyze_interaction_comparison(df, output_dir):
    """åˆ†æAI vs éAIäº’åŠ¨å¯¹æ¯”"""
    print("\n2ï¸âƒ£ åˆ†æäº’åŠ¨æŒ‡æ ‡å¯¹æ¯”...")

    ai_comments = df[df['video_type'] == 'ai_generated']
    non_ai_comments = df[df['video_type'] == 'non_ai']

    # åˆ›å»ºå¯¹æ¯”å›¾
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))

    # ç‚¹èµæ•°å¯¹æ¯”
    data_likes = [
        ai_comments['like_count'].values,
        non_ai_comments['like_count'].values
    ]

    axes[0].boxplot(data_likes, labels=['AI Content', 'Non-AI Content'])
    axes[0].set_ylabel('Like Count', fontweight='bold')
    axes[0].set_title('Like Count Distribution', fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='y')

    # è¯„è®ºé•¿åº¦å¯¹æ¯”
    ai_comments_copy = ai_comments.copy()
    non_ai_comments_copy = non_ai_comments.copy()
    ai_comments_copy['text_length'] = ai_comments_copy['text'].str.len()
    non_ai_comments_copy['text_length'] = non_ai_comments_copy['text'].str.len()

    data_length = [
        ai_comments_copy['text_length'].values,
        non_ai_comments_copy['text_length'].values
    ]

    axes[1].boxplot(data_length, labels=['AI Content', 'Non-AI Content'])
    axes[1].set_ylabel('Comment Length (characters)', fontweight='bold')
    axes[1].set_title('Comment Length Distribution', fontweight='bold')
    axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    output_file = output_dir / 'interaction_comparison.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ“ ä¿å­˜å›¾è¡¨: {output_file}")
    plt.close()

    stats = {
        'ai': {
            'avg_likes': ai_comments['like_count'].mean(),
            'median_likes': ai_comments['like_count'].median(),
            'avg_length': ai_comments_copy['text_length'].mean(),
            'median_length': ai_comments_copy['text_length'].median()
        },
        'non_ai': {
            'avg_likes': non_ai_comments['like_count'].mean(),
            'median_likes': non_ai_comments['like_count'].median(),
            'avg_length': non_ai_comments_copy['text_length'].mean(),
            'median_length': non_ai_comments_copy['text_length'].median()
        }
    }

    return stats

def analyze_ai_detection(df, output_dir):
    """åˆ†æAIæ£€æµ‹ç½®ä¿¡åº¦"""
    print("\n3ï¸âƒ£ åˆ†æAIæ£€æµ‹ç½®ä¿¡åº¦...")

    ai_comments = df[df['video_type'] == 'ai_generated']

    if len(ai_comments) == 0:
        print("   âš  æ²¡æœ‰AIè¯„è®º")
        return None

    # æå–ç½®ä¿¡åº¦
    confidences = []
    all_keywords = []

    for _, row in ai_comments.iterrows():
        ai_det = row['ai_detection']
        confidences.append(ai_det['confidence'])
        all_keywords.extend(ai_det.get('matched_keywords', []))

    # ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))

    axes[0].hist(confidences, bins=20, color='#4ECDC4', edgecolor='black', alpha=0.7)
    axes[0].set_xlabel('Confidence Score', fontweight='bold')
    axes[0].set_ylabel('Frequency', fontweight='bold')
    axes[0].set_title('AI Detection Confidence Distribution', fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='y')

    # å…³é”®è¯é¢‘ç‡
    keyword_counts = Counter(all_keywords)
    top_keywords = dict(keyword_counts.most_common(10))

    axes[1].barh(list(top_keywords.keys()), list(top_keywords.values()), color='#95E1D3')
    axes[1].set_xlabel('Frequency', fontweight='bold')
    axes[1].set_title('Top AI Keywords Detected', fontweight='bold')
    axes[1].grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    output_file = output_dir / 'ai_detection_analysis.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    print(f"   âœ“ ä¿å­˜å›¾è¡¨: {output_file}")
    plt.close()

    return {
        'avg_confidence': sum(confidences) / len(confidences),
        'min_confidence': min(confidences),
        'max_confidence': max(confidences),
        'top_keywords': list(top_keywords.items())[:5]
    }

def generate_report(df, quarter_stats, interaction_stats, detection_stats, output_dir):
    """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
    print("\n4ï¸âƒ£ ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_file = output_dir / f'analysis_report_{timestamp}.txt'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write("="*80 + "\n")
        f.write(" YouTube Shorts AI Content Analysis Report\n")
        f.write("="*80 + "\n\n")

        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"åˆ†æè¯„è®ºæ•°: {len(df):,}\n\n")

        # åŸºç¡€ç»Ÿè®¡
        f.write("="*80 + "\n")
        f.write("1. æ•°æ®æ¦‚è§ˆ\n")
        f.write("="*80 + "\n\n")

        f.write(f"æ—¶é—´èŒƒå›´: {df['published_at'].min()} ~ {df['published_at'].max()}\n")
        f.write(f"æ€»è¯„è®ºæ•°: {len(df):,}\n")
        f.write(f"è§†é¢‘æ•°: {df['video_id'].nunique()}\n")
        f.write(f"ä½œè€…æ•°: {df['author'].nunique()}\n\n")

        # AIå æ¯”
        ai_count = len(df[df['video_type'] == 'ai_generated'])
        non_ai_count = len(df[df['video_type'] == 'non_ai'])
        ai_ratio = ai_count / len(df) * 100

        f.write(f"AIå†…å®¹: {ai_count:,} ({ai_ratio:.1f}%)\n")
        f.write(f"éAIå†…å®¹: {non_ai_count:,} ({100-ai_ratio:.1f}%)\n\n")

        # AIå æ¯”æ¼”å˜
        f.write("="*80 + "\n")
        f.write("2. AIå æ¯”æ—¶é—´æ¼”å˜\n")
        f.write("="*80 + "\n\n")

        f.write(f"{'å­£åº¦':<12} {'AIè¯„è®º':<10} {'æ€»è¯„è®º':<10} {'AIå æ¯”':<10}\n")
        f.write("-"*42 + "\n")
        for quarter, row in quarter_stats.iterrows():
            f.write(f"{quarter:<12} {int(row['ai_count']):<10} {int(row['total']):<10} {row['ai_ratio']:<10.1f}%\n")

        # äº’åŠ¨å¯¹æ¯”
        f.write("\n" + "="*80 + "\n")
        f.write("3. AI vs éAI äº’åŠ¨å¯¹æ¯”\n")
        f.write("="*80 + "\n\n")

        f.write("AIå†…å®¹:\n")
        f.write(f"  å¹³å‡ç‚¹èµ: {interaction_stats['ai']['avg_likes']:.2f}\n")
        f.write(f"  ä¸­ä½æ•°ç‚¹èµ: {interaction_stats['ai']['median_likes']:.0f}\n")
        f.write(f"  å¹³å‡è¯„è®ºé•¿åº¦: {interaction_stats['ai']['avg_length']:.1f} å­—ç¬¦\n\n")

        f.write("éAIå†…å®¹:\n")
        f.write(f"  å¹³å‡ç‚¹èµ: {interaction_stats['non_ai']['avg_likes']:.2f}\n")
        f.write(f"  ä¸­ä½æ•°ç‚¹èµ: {interaction_stats['non_ai']['median_likes']:.0f}\n")
        f.write(f"  å¹³å‡è¯„è®ºé•¿åº¦: {interaction_stats['non_ai']['avg_length']:.1f} å­—ç¬¦\n\n")

        # AIæ£€æµ‹
        if detection_stats:
            f.write("="*80 + "\n")
            f.write("4. AIæ£€æµ‹ç»Ÿè®¡\n")
            f.write("="*80 + "\n\n")

            f.write(f"å¹³å‡ç½®ä¿¡åº¦: {detection_stats['avg_confidence']:.3f}\n")
            f.write(f"ç½®ä¿¡åº¦èŒƒå›´: {detection_stats['min_confidence']:.3f} ~ {detection_stats['max_confidence']:.3f}\n\n")

            f.write("æœ€å¸¸è§AIå…³é”®è¯:\n")
            for kw, count in detection_stats['top_keywords']:
                f.write(f"  â€¢ {kw}: {count}æ¬¡\n")

        f.write("\n" + "="*80 + "\n")
        f.write("æŠ¥å‘Šç»“æŸ\n")
        f.write("="*80 + "\n")

    print(f"   âœ“ ä¿å­˜æŠ¥å‘Š: {report_file}")

    return report_file

def main():
    if len(sys.argv) < 2:
        data_file = 'data/raw/comments_natural_distribution_20251020_200458.json'
        print(f"ä½¿ç”¨é»˜è®¤æ•°æ®æ–‡ä»¶: {data_file}")
    else:
        data_file = sys.argv[1]

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path('output/analysis')
    output_dir.mkdir(parents=True, exist_ok=True)

    print("="*80)
    print(" YouTube Shorts AI Content Analysis")
    print("="*80)

    # åŠ è½½æ•°æ®
    df = load_data(data_file)
    print(f"âœ… åŠ è½½ {len(df):,} æ¡è¯„è®º\n")

    # åˆ†æ
    quarter_stats = analyze_ai_ratio_evolution(df, output_dir)
    interaction_stats = analyze_interaction_comparison(df, output_dir)
    detection_stats = analyze_ai_detection(df, output_dir)
    report_file = generate_report(df, quarter_stats, interaction_stats, detection_stats, output_dir)

    print("\n" + "="*80)
    print(" âœ… åˆ†æå®Œæˆ!")
    print("="*80)
    print(f"\nğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ğŸ“Š å›¾è¡¨: {list(output_dir.glob('*.png'))}")
    print(f"ğŸ“„ æŠ¥å‘Š: {report_file}\n")

if __name__ == '__main__':
    main()
