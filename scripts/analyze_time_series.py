#!/usr/bin/env python3
"""
æ—¶é—´åºåˆ—åˆ†æè„šæœ¬

åˆ†æ 2022-2025 å¹´é—´è§‚ä¼—å¯¹ YouTube Shorts è¯„è®ºçš„æƒ…æ„Ÿã€ä¸»é¢˜ã€äº’åŠ¨æ¨¡å¼çš„æ—¶é—´æ¼”å˜

Usage:
    python scripts/analyze_time_series.py \
        --input data/processed/comments_sentiment_topics.csv \
        --output output/figures
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_and_prepare_data(input_file: str) -> pd.DataFrame:
    """
    åŠ è½½æ•°æ®å¹¶å‡†å¤‡æ—¶é—´åºåˆ—åˆ†æ

    Args:
        input_file: è¾“å…¥ CSV æ–‡ä»¶è·¯å¾„

    Returns:
        å¤„ç†åçš„ DataFrame
    """
    print(f"\nğŸ“Š åŠ è½½æ•°æ®: {input_file}")

    df = pd.read_csv(input_file)

    # è½¬æ¢æ—¶é—´å­—æ®µ
    if 'published_at' in df.columns:
        df['published_at'] = pd.to_datetime(df['published_at'], errors='coerce')

    # æå–æ—¶é—´ç‰¹å¾
    df['year'] = df['published_at'].dt.year
    df['month'] = df['published_at'].dt.month
    df['year_month'] = df['published_at'].dt.to_period('M')
    df['quarter'] = df['published_at'].dt.to_period('Q')

    # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
    df_valid = df[df['published_at'].notna()].copy()

    print(f"  æ€»è¯„è®ºæ•°: {len(df)}")
    print(f"  æœ‰æ•ˆæ—¶é—´æˆ³: {len(df_valid)}")
    print(f"  æ—¶é—´èŒƒå›´: {df_valid['published_at'].min()} åˆ° {df_valid['published_at'].max()}")

    return df_valid


def analyze_sentiment_over_time(df: pd.DataFrame, output_dir: Path):
    """
    åˆ†ææƒ…æ„Ÿéšæ—¶é—´çš„å˜åŒ–

    Args:
        df: è¾“å…¥æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ“ˆ åˆ†ææƒ…æ„Ÿæ—¶é—´åºåˆ—...")

    # æŒ‰æœˆç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
    sentiment_by_month = df.groupby(['year_month', 'sentiment']).size().unstack(fill_value=0)
    sentiment_by_month_pct = sentiment_by_month.div(sentiment_by_month.sum(axis=1), axis=0) * 100

    # ç»˜åˆ¶æƒ…æ„Ÿæ¼”å˜å›¾
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))

    # 1. ç»å¯¹æ•°é‡
    sentiment_by_month.plot(
        kind='area',
        stacked=True,
        alpha=0.7,
        ax=ax1,
        color=['#d32f2f', '#757575', '#388e3c']  # red, gray, green
    )
    ax1.set_title('è¯„è®ºæƒ…æ„Ÿåˆ†å¸ƒéšæ—¶é—´å˜åŒ–ï¼ˆç»å¯¹æ•°é‡ï¼‰', fontsize=14, fontweight='bold')
    ax1.set_xlabel('æ—¶é—´', fontsize=12)
    ax1.set_ylabel('è¯„è®ºæ•°', fontsize=12)
    ax1.legend(title='æƒ…æ„Ÿ', labels=['Negative', 'Neutral', 'Positive'], loc='upper left')
    ax1.grid(True, alpha=0.3)

    # 2. ç™¾åˆ†æ¯”
    sentiment_by_month_pct.plot(
        kind='line',
        ax=ax2,
        marker='o',
        linewidth=2,
        color=['#d32f2f', '#757575', '#388e3c']
    )
    ax2.set_title('è¯„è®ºæƒ…æ„Ÿæ¯”ä¾‹éšæ—¶é—´å˜åŒ–', fontsize=14, fontweight='bold')
    ax2.set_xlabel('æ—¶é—´', fontsize=12)
    ax2.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
    ax2.legend(title='æƒ…æ„Ÿ', labels=['Negative', 'Neutral', 'Positive'], loc='best')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 100)

    plt.tight_layout()
    output_file = output_dir / 'sentiment_time_series.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")

    # ä¿å­˜ç»Ÿè®¡æ•°æ®
    stats = {
        'sentiment_by_month': sentiment_by_month.to_dict(),
        'sentiment_by_month_percentage': sentiment_by_month_pct.to_dict()
    }

    return stats


def analyze_engagement_over_time(df: pd.DataFrame, output_dir: Path):
    """
    åˆ†æäº’åŠ¨æ•°æ®éšæ—¶é—´çš„å˜åŒ–

    Args:
        df: è¾“å…¥æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ’¬ åˆ†æäº’åŠ¨æ—¶é—´åºåˆ—...")

    # æŒ‰æœˆç»Ÿè®¡äº’åŠ¨æ•°æ®
    engagement_by_month = df.groupby('year_month').agg({
        'like_count': ['mean', 'median', 'sum'],
        'text': 'count'  # è¯„è®ºæ•°
    }).reset_index()

    engagement_by_month.columns = ['year_month', 'mean_likes', 'median_likes', 'total_likes', 'comment_count']

    # ç»˜åˆ¶äº’åŠ¨æ¼”å˜å›¾
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(14, 10))

    # 1. å¹³å‡ç‚¹èµæ•°
    ax1.plot(engagement_by_month['year_month'].astype(str),
             engagement_by_month['mean_likes'],
             marker='o', linewidth=2, color='#1976d2', label='å¹³å‡ç‚¹èµæ•°')
    ax1.plot(engagement_by_month['year_month'].astype(str),
             engagement_by_month['median_likes'],
             marker='s', linewidth=2, color='#ff9800', label='ä¸­ä½æ•°ç‚¹èµæ•°', linestyle='--')
    ax1.set_title('å¹³å‡ç‚¹èµæ•°éšæ—¶é—´å˜åŒ–', fontsize=14, fontweight='bold')
    ax1.set_xlabel('æ—¶é—´', fontsize=12)
    ax1.set_ylabel('ç‚¹èµæ•°', fontsize=12)
    ax1.legend(loc='best')
    ax1.grid(True, alpha=0.3)
    ax1.tick_params(axis='x', rotation=45)

    # 2. è¯„è®ºæ•°é‡
    ax2.bar(engagement_by_month['year_month'].astype(str),
            engagement_by_month['comment_count'],
            color='#4caf50', alpha=0.7)
    ax2.set_title('è¯„è®ºæ•°é‡éšæ—¶é—´å˜åŒ–', fontsize=14, fontweight='bold')
    ax2.set_xlabel('æ—¶é—´', fontsize=12)
    ax2.set_ylabel('è¯„è®ºæ•°', fontsize=12)
    ax2.grid(True, alpha=0.3, axis='y')
    ax2.tick_params(axis='x', rotation=45)

    plt.tight_layout()
    output_file = output_dir / 'engagement_time_series.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")

    stats = {
        'engagement_by_month': engagement_by_month.to_dict(orient='records')
    }

    return stats


def analyze_topics_over_time(df: pd.DataFrame, output_dir: Path):
    """
    åˆ†æä¸»é¢˜åˆ†å¸ƒéšæ—¶é—´çš„å˜åŒ–

    Args:
        df: è¾“å…¥æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ·ï¸  åˆ†æä¸»é¢˜æ—¶é—´åºåˆ—...")

    if 'topic' not in df.columns:
        print("  âš ï¸  æœªæ‰¾åˆ°ä¸»é¢˜å­—æ®µï¼Œè·³è¿‡ä¸»é¢˜æ—¶é—´åºåˆ—åˆ†æ")
        return {}

    # è¿‡æ»¤æœ‰æ•ˆä¸»é¢˜
    df_topics = df[df['topic'] >= 0].copy()

    if len(df_topics) == 0:
        print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„ä¸»é¢˜æ•°æ®")
        return {}

    # æŒ‰æœˆç»Ÿè®¡ä¸»é¢˜åˆ†å¸ƒ
    topic_by_month = df_topics.groupby(['year_month', 'topic']).size().unstack(fill_value=0)
    topic_by_month_pct = topic_by_month.div(topic_by_month.sum(axis=1), axis=0) * 100

    # ç»˜åˆ¶ä¸»é¢˜æ¼”å˜å›¾
    fig, ax = plt.subplots(figsize=(14, 8))

    topic_by_month_pct.plot(
        kind='area',
        stacked=True,
        alpha=0.7,
        ax=ax,
        colormap='tab10'
    )

    ax.set_title('ä¸»é¢˜åˆ†å¸ƒéšæ—¶é—´å˜åŒ–', fontsize=14, fontweight='bold')
    ax.set_xlabel('æ—¶é—´', fontsize=12)
    ax.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
    ax.legend(title='ä¸»é¢˜', labels=[f'Topic {i}' for i in topic_by_month_pct.columns],
              loc='center left', bbox_to_anchor=(1, 0.5))
    ax.grid(True, alpha=0.3)
    ax.set_ylim(0, 100)

    plt.tight_layout()
    output_file = output_dir / 'topics_time_series.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")

    stats = {
        'topic_by_month_percentage': topic_by_month_pct.to_dict()
    }

    return stats


def analyze_ai_content_evolution(df: pd.DataFrame, output_dir: Path):
    """
    åˆ†æ AI å†…å®¹éšæ—¶é—´çš„æ¼”å˜ï¼ˆå¦‚æœæœ‰ video_type å­—æ®µï¼‰

    Args:
        df: è¾“å…¥æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ¤– åˆ†æ AI å†…å®¹æ—¶é—´æ¼”å˜...")

    if 'video_type' not in df.columns:
        print("  âš ï¸  æœªæ‰¾åˆ° video_type å­—æ®µï¼Œè·³è¿‡ AI å†…å®¹æ¼”å˜åˆ†æ")
        return {}

    # æŒ‰æœˆç»Ÿè®¡ AI vs éAI
    ai_by_month = df.groupby(['year_month', 'video_type']).size().unstack(fill_value=0)

    if ai_by_month.empty:
        print("  âš ï¸  æ²¡æœ‰ AI ç±»å‹æ•°æ®")
        return {}

    ai_by_month_pct = ai_by_month.div(ai_by_month.sum(axis=1), axis=0) * 100

    # ç»˜åˆ¶ AI å†…å®¹æ¯”ä¾‹æ¼”å˜
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

    # 1. ç»å¯¹æ•°é‡
    ai_by_month.plot(kind='bar', stacked=True, ax=ax1, color=['#ff6b6b', '#4ecdc4'])
    ax1.set_title('AI vs éAI å†…å®¹æ•°é‡éšæ—¶é—´å˜åŒ–', fontsize=14, fontweight='bold')
    ax1.set_xlabel('æ—¶é—´', fontsize=12)
    ax1.set_ylabel('è¯„è®ºæ•°', fontsize=12)
    ax1.legend(title='å†…å®¹ç±»å‹', labels=['AI Generated', 'Non-AI'], loc='upper left')
    ax1.tick_params(axis='x', rotation=45)
    ax1.grid(True, alpha=0.3, axis='y')

    # 2. ç™¾åˆ†æ¯”
    ai_by_month_pct.plot(kind='line', marker='o', linewidth=2, ax=ax2, color=['#ff6b6b', '#4ecdc4'])
    ax2.set_title('AI å†…å®¹æ¯”ä¾‹éšæ—¶é—´å˜åŒ–', fontsize=14, fontweight='bold')
    ax2.set_xlabel('æ—¶é—´', fontsize=12)
    ax2.set_ylabel('ç™¾åˆ†æ¯” (%)', fontsize=12)
    ax2.legend(title='å†…å®¹ç±»å‹', labels=['AI Generated', 'Non-AI'], loc='best')
    ax2.grid(True, alpha=0.3)
    ax2.set_ylim(0, 100)

    plt.tight_layout()
    output_file = output_dir / 'ai_content_evolution.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")

    stats = {
        'ai_by_month': ai_by_month.to_dict(),
        'ai_by_month_percentage': ai_by_month_pct.to_dict()
    }

    return stats


def analyze_yearly_comparison(df: pd.DataFrame, output_dir: Path):
    """
    å¹´åº¦å¯¹æ¯”åˆ†æ

    Args:
        df: è¾“å…¥æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ“… å¹´åº¦å¯¹æ¯”åˆ†æ...")

    # æŒ‰å¹´ç»Ÿè®¡
    yearly_stats = df.groupby('year').agg({
        'text': 'count',
        'like_count': ['mean', 'median', 'sum'],
        'sentiment': lambda x: (x == 'positive').sum() / len(x) * 100
    }).reset_index()

    yearly_stats.columns = ['year', 'comment_count', 'mean_likes', 'median_likes',
                            'total_likes', 'positive_ratio']

    # ç»˜åˆ¶å¹´åº¦å¯¹æ¯”å›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. è¯„è®ºæ•°é‡
    axes[0, 0].bar(yearly_stats['year'], yearly_stats['comment_count'],
                   color='#2196f3', alpha=0.7)
    axes[0, 0].set_title('å¹´åº¦è¯„è®ºæ•°é‡', fontsize=12, fontweight='bold')
    axes[0, 0].set_xlabel('å¹´ä»½', fontsize=10)
    axes[0, 0].set_ylabel('è¯„è®ºæ•°', fontsize=10)
    axes[0, 0].grid(True, alpha=0.3, axis='y')

    # 2. å¹³å‡ç‚¹èµæ•°
    axes[0, 1].plot(yearly_stats['year'], yearly_stats['mean_likes'],
                    marker='o', linewidth=2, color='#ff9800', markersize=8)
    axes[0, 1].set_title('å¹´åº¦å¹³å‡ç‚¹èµæ•°', fontsize=12, fontweight='bold')
    axes[0, 1].set_xlabel('å¹´ä»½', fontsize=10)
    axes[0, 1].set_ylabel('å¹³å‡ç‚¹èµ', fontsize=10)
    axes[0, 1].grid(True, alpha=0.3)

    # 3. ç§¯ææƒ…æ„Ÿæ¯”ä¾‹
    axes[1, 0].plot(yearly_stats['year'], yearly_stats['positive_ratio'],
                    marker='s', linewidth=2, color='#4caf50', markersize=8)
    axes[1, 0].set_title('å¹´åº¦ç§¯ææƒ…æ„Ÿæ¯”ä¾‹', fontsize=12, fontweight='bold')
    axes[1, 0].set_xlabel('å¹´ä»½', fontsize=10)
    axes[1, 0].set_ylabel('ç§¯ææ¯”ä¾‹ (%)', fontsize=10)
    axes[1, 0].grid(True, alpha=0.3)
    axes[1, 0].set_ylim(0, 100)

    # 4. æ€»ç‚¹èµæ•°
    axes[1, 1].bar(yearly_stats['year'], yearly_stats['total_likes'],
                   color='#9c27b0', alpha=0.7)
    axes[1, 1].set_title('å¹´åº¦æ€»ç‚¹èµæ•°', fontsize=12, fontweight='bold')
    axes[1, 1].set_xlabel('å¹´ä»½', fontsize=10)
    axes[1, 1].set_ylabel('æ€»ç‚¹èµ', fontsize=10)
    axes[1, 1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    output_file = output_dir / 'yearly_comparison.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")

    stats = {
        'yearly_stats': yearly_stats.to_dict(orient='records')
    }

    return stats


def generate_time_series_report(all_stats: dict, df: pd.DataFrame, output_dir: Path):
    """
    ç”Ÿæˆæ—¶é—´åºåˆ—åˆ†ææŠ¥å‘Š

    Args:
        all_stats: æ‰€æœ‰ç»Ÿè®¡æ•°æ®
        df: åŸå§‹æ•°æ®
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ“ ç”Ÿæˆæ—¶é—´åºåˆ—åˆ†ææŠ¥å‘Š...")

    report = []

    report.append("=" * 80)
    report.append("æ—¶é—´åºåˆ—åˆ†ææŠ¥å‘Š")
    report.append("YouTube Shorts è¯„è®ºæ—¶é—´æ¼”å˜åˆ†æ (2022-2025)")
    report.append("=" * 80)
    report.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")

    # 1. æ•°æ®æ¦‚è§ˆ
    report.append("=" * 80)
    report.append("1. æ•°æ®æ¦‚è§ˆ")
    report.append("=" * 80)
    report.append(f"\næ€»è¯„è®ºæ•°: {len(df):,}")
    report.append(f"æ—¶é—´èŒƒå›´: {df['published_at'].min()} åˆ° {df['published_at'].max()}")
    report.append(f"è·¨åº¦: {(df['published_at'].max() - df['published_at'].min()).days} å¤©")

    # å¹´åº¦åˆ†å¸ƒ
    year_counts = df['year'].value_counts().sort_index()
    report.append(f"\nå¹´åº¦åˆ†å¸ƒ:")
    for year, count in year_counts.items():
        report.append(f"  {int(year)}: {count:,} æ¡è¯„è®º")
    report.append("")

    # 2. æƒ…æ„Ÿæ¼”å˜
    report.append("=" * 80)
    report.append("2. æƒ…æ„Ÿæ¼”å˜è¶‹åŠ¿")
    report.append("=" * 80)
    report.append("")

    # è®¡ç®—æƒ…æ„Ÿè¶‹åŠ¿
    sentiment_trend = df.groupby('year')['sentiment'].value_counts(normalize=True).unstack(fill_value=0) * 100
    report.append("å¹´åº¦æƒ…æ„Ÿåˆ†å¸ƒ:")
    for year in sentiment_trend.index:
        report.append(f"\n  {int(year)} å¹´:")
        for sentiment in ['positive', 'neutral', 'negative']:
            if sentiment in sentiment_trend.columns:
                report.append(f"    {sentiment}: {sentiment_trend.loc[year, sentiment]:.1f}%")
    report.append("")

    # 3. äº’åŠ¨æ¼”å˜
    report.append("=" * 80)
    report.append("3. äº’åŠ¨æ•°æ®æ¼”å˜")
    report.append("=" * 80)
    report.append("")

    engagement_yearly = df.groupby('year')['like_count'].agg(['mean', 'median', 'sum'])
    report.append("å¹´åº¦ç‚¹èµæ•°æ®:")
    for year in engagement_yearly.index:
        report.append(f"\n  {int(year)} å¹´:")
        report.append(f"    å¹³å‡ç‚¹èµ: {engagement_yearly.loc[year, 'mean']:.2f}")
        report.append(f"    ä¸­ä½æ•°: {engagement_yearly.loc[year, 'median']:.0f}")
        report.append(f"    æ€»ç‚¹èµ: {engagement_yearly.loc[year, 'sum']:,.0f}")
    report.append("")

    # 4. å…³é”®å‘ç°
    report.append("=" * 80)
    report.append("4. å…³é”®å‘ç°")
    report.append("=" * 80)
    report.append("")

    findings = []

    # æƒ…æ„Ÿå˜åŒ–
    if len(sentiment_trend) >= 2:
        years = sorted(sentiment_trend.index)
        first_year = years[0]
        last_year = years[-1]

        if 'positive' in sentiment_trend.columns:
            pos_change = sentiment_trend.loc[last_year, 'positive'] - sentiment_trend.loc[first_year, 'positive']
            if abs(pos_change) > 5:
                direction = "ä¸Šå‡" if pos_change > 0 else "ä¸‹é™"
                findings.append(f"â€¢ ç§¯ææƒ…æ„Ÿæ¯”ä¾‹ä» {int(first_year)} åˆ° {int(last_year)} {direction}äº† {abs(pos_change):.1f}%")

    # äº’åŠ¨å˜åŒ–
    if len(engagement_yearly) >= 2:
        years = sorted(engagement_yearly.index)
        first_year = years[0]
        last_year = years[-1]

        engagement_change = ((engagement_yearly.loc[last_year, 'mean'] / engagement_yearly.loc[first_year, 'mean']) - 1) * 100
        if abs(engagement_change) > 10:
            direction = "å¢é•¿" if engagement_change > 0 else "ä¸‹é™"
            findings.append(f"â€¢ å¹³å‡ç‚¹èµæ•°ä» {int(first_year)} åˆ° {int(last_year)} {direction}äº† {abs(engagement_change):.1f}%")

    if findings:
        report.extend(findings)
    else:
        report.append("â€¢ æœªå‘ç°æ˜¾è‘—çš„æ—¶é—´è¶‹åŠ¿å˜åŒ–")

    report.append("")
    report.append("=" * 80)
    report.append("æŠ¥å‘Šç»“æŸ")
    report.append("=" * 80)

    # ä¿å­˜æŠ¥å‘Š
    report_text = '\n'.join(report)
    report_file = output_dir / f'time_series_report_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"  âœ“ ä¿å­˜: {report_file}")

    return report_text


def main():
    parser = argparse.ArgumentParser(description='æ—¶é—´åºåˆ—åˆ†æ')
    parser.add_argument('--input', required=True, help='è¾“å…¥ CSV æ–‡ä»¶')
    parser.add_argument('--output', default='output/figures', help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    print("=" * 80)
    print(" æ—¶é—´åºåˆ—åˆ†æå·¥å…·")
    print("=" * 80)

    # åŠ è½½æ•°æ®
    df = load_and_prepare_data(args.input)

    if len(df) == 0:
        print("\nâŒ æ²¡æœ‰æœ‰æ•ˆçš„æ—¶é—´æˆ³æ•°æ®")
        return 1

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # æ‰§è¡Œå„é¡¹åˆ†æ
    all_stats = {}

    all_stats['sentiment'] = analyze_sentiment_over_time(df, output_dir)
    all_stats['engagement'] = analyze_engagement_over_time(df, output_dir)
    all_stats['topics'] = analyze_topics_over_time(df, output_dir)
    all_stats['ai_evolution'] = analyze_ai_content_evolution(df, output_dir)
    all_stats['yearly'] = analyze_yearly_comparison(df, output_dir)

    # ç”ŸæˆæŠ¥å‘Š
    report_text = generate_time_series_report(all_stats, df, output_dir)

    # ä¿å­˜ç»Ÿè®¡æ•°æ®
    stats_file = output_dir / f'time_series_stats_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(stats_file, 'w', encoding='utf-8') as f:
        json.dump(all_stats, f, ensure_ascii=False, indent=2, default=str)

    print(f"\nâœ… æ—¶é—´åºåˆ—åˆ†æå®Œæˆï¼")
    print(f"\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - sentiment_time_series.png")
    print(f"  - engagement_time_series.png")
    print(f"  - topics_time_series.png")
    print(f"  - yearly_comparison.png")
    print(f"  - time_series_report_*.txt")
    print(f"  - time_series_stats_*.json")
    print()

    return 0


if __name__ == '__main__':
    sys.exit(main())
