#!/usr/bin/env python3
"""
AI vs éAI å†…å®¹å¯¹æ¯”åˆ†æ

å¯¹æ¯” AI ç”Ÿæˆå†…å®¹å’Œé AI å†…å®¹åœ¨æƒ…æ„Ÿã€ä¸»é¢˜ã€äº’åŠ¨ç­‰æ–¹é¢çš„å·®å¼‚

Usage:
    python scripts/compare_ai_nonai.py \
        --ai data/processed/comments_ai_sentiment_topics.csv \
        --non-ai data/processed/comments_non_ai_sentiment_topics.csv
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
from datetime import datetime
from scipy import stats

def calculate_statistics(df_ai, df_non_ai):
    """è®¡ç®—ç»Ÿè®¡æ•°æ®"""

    results = {
        'sample_sizes': {
            'ai': len(df_ai),
            'non_ai': len(df_non_ai)
        }
    }

    # 1. æƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯”
    ai_sentiment = df_ai['sentiment'].value_counts(normalize=True)
    non_ai_sentiment = df_non_ai['sentiment'].value_counts(normalize=True)

    results['sentiment_distribution'] = {
        'ai': ai_sentiment.to_dict(),
        'non_ai': non_ai_sentiment.to_dict()
    }

    # å¡æ–¹æ£€éªŒ - æƒ…æ„Ÿåˆ†å¸ƒå·®å¼‚
    if 'sentiment' in df_ai.columns and 'sentiment' in df_non_ai.columns:
        contingency_table = pd.crosstab(
            pd.concat([df_ai, df_non_ai])['sentiment'],
            pd.concat([
                pd.Series(['AI']*len(df_ai)),
                pd.Series(['Non-AI']*len(df_non_ai))
            ])
        )
        chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)
        results['sentiment_chi2_test'] = {
            'chi2': float(chi2),
            'p_value': float(p_value),
            'significant': p_value < 0.05
        }

    # 2. æƒ…æ„Ÿç½®ä¿¡åº¦å¯¹æ¯”
    if 'sentiment_confidence' in df_ai.columns and 'sentiment_confidence' in df_non_ai.columns:
        results['sentiment_confidence'] = {
            'ai': {
                'mean': float(df_ai['sentiment_confidence'].mean()),
                'median': float(df_ai['sentiment_confidence'].median()),
                'std': float(df_ai['sentiment_confidence'].std())
            },
            'non_ai': {
                'mean': float(df_non_ai['sentiment_confidence'].mean()),
                'median': float(df_non_ai['sentiment_confidence'].median()),
                'std': float(df_non_ai['sentiment_confidence'].std())
            }
        }

        # Tæ£€éªŒ - ç½®ä¿¡åº¦å·®å¼‚
        t_stat, p_value = stats.ttest_ind(
            df_ai['sentiment_confidence'].dropna(),
            df_non_ai['sentiment_confidence'].dropna()
        )
        results['confidence_ttest'] = {
            't_statistic': float(t_stat),
            'p_value': float(p_value),
            'significant': p_value < 0.05
        }

    # 3. äº’åŠ¨æ•°æ®å¯¹æ¯”
    if 'like_count' in df_ai.columns and 'like_count' in df_non_ai.columns:
        results['engagement'] = {
            'ai': {
                'total_likes': int(df_ai['like_count'].sum()),
                'mean_likes': float(df_ai['like_count'].mean()),
                'median_likes': float(df_ai['like_count'].median()),
                'max_likes': int(df_ai['like_count'].max())
            },
            'non_ai': {
                'total_likes': int(df_non_ai['like_count'].sum()),
                'mean_likes': float(df_non_ai['like_count'].mean()),
                'median_likes': float(df_non_ai['like_count'].median()),
                'max_likes': int(df_non_ai['like_count'].max())
            }
        }

        # Mann-Whitney U æ£€éªŒ - ç‚¹èµæ•°å·®å¼‚ï¼ˆéå‚æ•°æ£€éªŒï¼‰
        u_stat, p_value = stats.mannwhitneyu(
            df_ai['like_count'].dropna(),
            df_non_ai['like_count'].dropna(),
            alternative='two-sided'
        )
        results['likes_mannwhitney'] = {
            'u_statistic': float(u_stat),
            'p_value': float(p_value),
            'significant': p_value < 0.05
        }

    # 4. ä¸»é¢˜åˆ†å¸ƒå¯¹æ¯”
    if 'topic' in df_ai.columns and 'topic' in df_non_ai.columns:
        ai_topics = df_ai[df_ai['topic'] >= 0]['topic'].value_counts(normalize=True)
        non_ai_topics = df_non_ai[df_non_ai['topic'] >= 0]['topic'].value_counts(normalize=True)

        results['topic_distribution'] = {
            'ai': ai_topics.to_dict(),
            'non_ai': non_ai_topics.to_dict()
        }

    # 5. æ–‡æœ¬é•¿åº¦å¯¹æ¯”
    if 'text_length' in df_ai.columns and 'text_length' in df_non_ai.columns:
        results['text_length'] = {
            'ai': {
                'mean': float(df_ai['text_length'].mean()),
                'median': float(df_ai['text_length'].median()),
                'std': float(df_ai['text_length'].std())
            },
            'non_ai': {
                'mean': float(df_non_ai['text_length'].mean()),
                'median': float(df_non_ai['text_length'].median()),
                'std': float(df_non_ai['text_length'].std())
            }
        }

        # Tæ£€éªŒ - æ–‡æœ¬é•¿åº¦å·®å¼‚
        t_stat, p_value = stats.ttest_ind(
            df_ai['text_length'].dropna(),
            df_non_ai['text_length'].dropna()
        )
        results['length_ttest'] = {
            't_statistic': float(t_stat),
            'p_value': float(p_value),
            'significant': p_value < 0.05
        }

    # 6. æƒ…æ„Ÿ-ä¸»é¢˜äº¤å‰åˆ†æ
    if 'sentiment' in df_ai.columns and 'topic' in df_ai.columns:
        # AI å†…å®¹çš„æƒ…æ„Ÿ-ä¸»é¢˜åˆ†å¸ƒ
        ai_cross = pd.crosstab(
            df_ai[df_ai['topic'] >= 0]['topic'],
            df_ai[df_ai['topic'] >= 0]['sentiment'],
            normalize='index'
        )

        # éAI å†…å®¹çš„æƒ…æ„Ÿ-ä¸»é¢˜åˆ†å¸ƒ
        non_ai_cross = pd.crosstab(
            df_non_ai[df_non_ai['topic'] >= 0]['topic'],
            df_non_ai[df_non_ai['topic'] >= 0]['sentiment'],
            normalize='index'
        )

        results['sentiment_topic_cross'] = {
            'ai': ai_cross.to_dict(),
            'non_ai': non_ai_cross.to_dict()
        }

    return results


def generate_report(results, df_ai, df_non_ai):
    """ç”Ÿæˆå¯¹æ¯”åˆ†ææŠ¥å‘Š"""

    report = []

    report.append("="*70)
    report.append("AI vs éAI å†…å®¹å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    report.append("="*70)
    report.append(f"\nç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append("")

    # 1. æ ·æœ¬ä¿¡æ¯
    report.append("="*70)
    report.append("1. æ ·æœ¬ä¿¡æ¯")
    report.append("="*70)
    report.append(f"\nAI å†…å®¹è¯„è®ºæ•°: {results['sample_sizes']['ai']}")
    report.append(f"é AI å†…å®¹è¯„è®ºæ•°: {results['sample_sizes']['non_ai']}")
    report.append(f"æ€»è®¡: {results['sample_sizes']['ai'] + results['sample_sizes']['non_ai']}")
    report.append("")

    # 2. æƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯”
    report.append("="*70)
    report.append("2. æƒ…æ„Ÿåˆ†å¸ƒå¯¹æ¯”")
    report.append("="*70)
    report.append("")

    report.append("AI å†…å®¹æƒ…æ„Ÿåˆ†å¸ƒ:")
    for sentiment, ratio in results['sentiment_distribution']['ai'].items():
        report.append(f"  {sentiment}: {ratio*100:.1f}%")

    report.append("\né AI å†…å®¹æƒ…æ„Ÿåˆ†å¸ƒ:")
    for sentiment, ratio in results['sentiment_distribution']['non_ai'].items():
        report.append(f"  {sentiment}: {ratio*100:.1f}%")

    # æƒ…æ„Ÿåˆ†å¸ƒæ˜¾è‘—æ€§æ£€éªŒ
    if 'sentiment_chi2_test' in results:
        report.append(f"\nå¡æ–¹æ£€éªŒç»“æœ:")
        report.append(f"  Ï‡Â² = {results['sentiment_chi2_test']['chi2']:.4f}")
        report.append(f"  p-value = {results['sentiment_chi2_test']['p_value']:.4f}")
        if results['sentiment_chi2_test']['significant']:
            report.append(f"  â­ ç»“è®º: æƒ…æ„Ÿåˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚ (p < 0.05)")
        else:
            report.append(f"  ç»“è®º: æƒ…æ„Ÿåˆ†å¸ƒæ— æ˜¾è‘—å·®å¼‚ (p >= 0.05)")
    report.append("")

    # 3. æƒ…æ„Ÿç½®ä¿¡åº¦å¯¹æ¯”
    if 'sentiment_confidence' in results:
        report.append("="*70)
        report.append("3. æƒ…æ„Ÿç½®ä¿¡åº¦å¯¹æ¯”")
        report.append("="*70)
        report.append("")

        report.append("AI å†…å®¹:")
        report.append(f"  å¹³å‡ç½®ä¿¡åº¦: {results['sentiment_confidence']['ai']['mean']:.3f}")
        report.append(f"  ä¸­ä½æ•°: {results['sentiment_confidence']['ai']['median']:.3f}")
        report.append(f"  æ ‡å‡†å·®: {results['sentiment_confidence']['ai']['std']:.3f}")

        report.append("\né AI å†…å®¹:")
        report.append(f"  å¹³å‡ç½®ä¿¡åº¦: {results['sentiment_confidence']['non_ai']['mean']:.3f}")
        report.append(f"  ä¸­ä½æ•°: {results['sentiment_confidence']['non_ai']['median']:.3f}")
        report.append(f"  æ ‡å‡†å·®: {results['sentiment_confidence']['non_ai']['std']:.3f}")

        if 'confidence_ttest' in results:
            report.append(f"\nTæ£€éªŒç»“æœ:")
            report.append(f"  t = {results['confidence_ttest']['t_statistic']:.4f}")
            report.append(f"  p-value = {results['confidence_ttest']['p_value']:.4f}")
            if results['confidence_ttest']['significant']:
                report.append(f"  â­ ç»“è®º: ç½®ä¿¡åº¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ (p < 0.05)")
            else:
                report.append(f"  ç»“è®º: ç½®ä¿¡åº¦æ— æ˜¾è‘—å·®å¼‚ (p >= 0.05)")
        report.append("")

    # 4. äº’åŠ¨æ•°æ®å¯¹æ¯”
    if 'engagement' in results:
        report.append("="*70)
        report.append("4. äº’åŠ¨æ•°æ®å¯¹æ¯”")
        report.append("="*70)
        report.append("")

        report.append("AI å†…å®¹:")
        report.append(f"  æ€»ç‚¹èµæ•°: {results['engagement']['ai']['total_likes']}")
        report.append(f"  å¹³å‡ç‚¹èµ: {results['engagement']['ai']['mean_likes']:.2f}")
        report.append(f"  ä¸­ä½æ•°: {results['engagement']['ai']['median_likes']:.0f}")
        report.append(f"  æœ€é«˜ç‚¹èµ: {results['engagement']['ai']['max_likes']}")

        report.append("\né AI å†…å®¹:")
        report.append(f"  æ€»ç‚¹èµæ•°: {results['engagement']['non_ai']['total_likes']}")
        report.append(f"  å¹³å‡ç‚¹èµ: {results['engagement']['non_ai']['mean_likes']:.2f}")
        report.append(f"  ä¸­ä½æ•°: {results['engagement']['non_ai']['median_likes']:.0f}")
        report.append(f"  æœ€é«˜ç‚¹èµ: {results['engagement']['non_ai']['max_likes']}")

        # è®¡ç®—æ¯”ç‡
        ai_avg = results['engagement']['ai']['mean_likes']
        non_ai_avg = results['engagement']['non_ai']['mean_likes']
        if non_ai_avg > 0:
            ratio = ai_avg / non_ai_avg
            report.append(f"\nâ­ AI å†…å®¹å¹³å‡ç‚¹èµæ˜¯é AI çš„ {ratio:.2f} å€")

        if 'likes_mannwhitney' in results:
            report.append(f"\nMann-Whitney U æ£€éªŒç»“æœ:")
            report.append(f"  U = {results['likes_mannwhitney']['u_statistic']:.2f}")
            report.append(f"  p-value = {results['likes_mannwhitney']['p_value']:.4f}")
            if results['likes_mannwhitney']['significant']:
                report.append(f"  â­ ç»“è®º: ç‚¹èµæ•°å­˜åœ¨æ˜¾è‘—å·®å¼‚ (p < 0.05)")
            else:
                report.append(f"  ç»“è®º: ç‚¹èµæ•°æ— æ˜¾è‘—å·®å¼‚ (p >= 0.05)")
        report.append("")

    # 5. ä¸»é¢˜åˆ†å¸ƒå¯¹æ¯”
    if 'topic_distribution' in results:
        report.append("="*70)
        report.append("5. ä¸»é¢˜åˆ†å¸ƒå¯¹æ¯”")
        report.append("="*70)
        report.append("")

        report.append("AI å†…å®¹ä¸»é¢˜åˆ†å¸ƒ:")
        for topic, ratio in sorted(results['topic_distribution']['ai'].items()):
            report.append(f"  ä¸»é¢˜ {int(topic)}: {ratio*100:.1f}%")

        report.append("\né AI å†…å®¹ä¸»é¢˜åˆ†å¸ƒ:")
        for topic, ratio in sorted(results['topic_distribution']['non_ai'].items()):
            report.append(f"  ä¸»é¢˜ {int(topic)}: {ratio*100:.1f}%")
        report.append("")

    # 6. æ–‡æœ¬é•¿åº¦å¯¹æ¯”
    if 'text_length' in results:
        report.append("="*70)
        report.append("6. æ–‡æœ¬é•¿åº¦å¯¹æ¯”")
        report.append("="*70)
        report.append("")

        report.append("AI å†…å®¹:")
        report.append(f"  å¹³å‡é•¿åº¦: {results['text_length']['ai']['mean']:.1f} å­—ç¬¦")
        report.append(f"  ä¸­ä½æ•°: {results['text_length']['ai']['median']:.0f} å­—ç¬¦")

        report.append("\né AI å†…å®¹:")
        report.append(f"  å¹³å‡é•¿åº¦: {results['text_length']['non_ai']['mean']:.1f} å­—ç¬¦")
        report.append(f"  ä¸­ä½æ•°: {results['text_length']['non_ai']['median']:.0f} å­—ç¬¦")

        if 'length_ttest' in results:
            report.append(f"\nTæ£€éªŒç»“æœ:")
            report.append(f"  t = {results['length_ttest']['t_statistic']:.4f}")
            report.append(f"  p-value = {results['length_ttest']['p_value']:.4f}")
            if results['length_ttest']['significant']:
                report.append(f"  â­ ç»“è®º: æ–‡æœ¬é•¿åº¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ (p < 0.05)")
            else:
                report.append(f"  ç»“è®º: æ–‡æœ¬é•¿åº¦æ— æ˜¾è‘—å·®å¼‚ (p >= 0.05)")
        report.append("")

    # 7. å…³é”®å‘ç°æ€»ç»“
    report.append("="*70)
    report.append("7. å…³é”®å‘ç°æ€»ç»“")
    report.append("="*70)
    report.append("")

    findings = []

    # æƒ…æ„Ÿå·®å¼‚
    if 'sentiment_chi2_test' in results and results['sentiment_chi2_test']['significant']:
        ai_pos = results['sentiment_distribution']['ai'].get('positive', 0)
        non_ai_pos = results['sentiment_distribution']['non_ai'].get('positive', 0)
        if ai_pos > non_ai_pos:
            findings.append(f"â€¢ AI å†…å®¹çš„ç§¯ææƒ…æ„Ÿæ¯”ä¾‹æ›´é«˜ ({ai_pos*100:.1f}% vs {non_ai_pos*100:.1f}%)")
        else:
            findings.append(f"â€¢ é AI å†…å®¹çš„ç§¯ææƒ…æ„Ÿæ¯”ä¾‹æ›´é«˜ ({non_ai_pos*100:.1f}% vs {ai_pos*100:.1f}%)")

    # äº’åŠ¨å·®å¼‚
    if 'likes_mannwhitney' in results and results['likes_mannwhitney']['significant']:
        ai_avg = results['engagement']['ai']['mean_likes']
        non_ai_avg = results['engagement']['non_ai']['mean_likes']
        if ai_avg > non_ai_avg:
            findings.append(f"â€¢ AI å†…å®¹è·å¾—æ›´å¤šäº’åŠ¨ï¼ˆå¹³å‡ {ai_avg:.2f} vs {non_ai_avg:.2f} èµï¼‰")
        else:
            findings.append(f"â€¢ é AI å†…å®¹è·å¾—æ›´å¤šäº’åŠ¨ï¼ˆå¹³å‡ {non_ai_avg:.2f} vs {ai_avg:.2f} èµï¼‰")

    # æ–‡æœ¬é•¿åº¦å·®å¼‚
    if 'length_ttest' in results and results['length_ttest']['significant']:
        ai_len = results['text_length']['ai']['mean']
        non_ai_len = results['text_length']['non_ai']['mean']
        if ai_len > non_ai_len:
            findings.append(f"â€¢ AI å†…å®¹è¯„è®ºæ›´é•¿ï¼ˆå¹³å‡ {ai_len:.1f} vs {non_ai_len:.1f} å­—ç¬¦ï¼‰")
        else:
            findings.append(f"â€¢ é AI å†…å®¹è¯„è®ºæ›´é•¿ï¼ˆå¹³å‡ {non_ai_len:.1f} vs {ai_len:.1f} å­—ç¬¦ï¼‰")

    if findings:
        report.extend(findings)
    else:
        report.append("â€¢ æœªå‘ç°ç»Ÿè®¡å­¦ä¸Šæ˜¾è‘—çš„å·®å¼‚")

    report.append("")
    report.append("="*70)
    report.append("æŠ¥å‘Šç»“æŸ")
    report.append("="*70)

    return '\n'.join(report)


def main():
    parser = argparse.ArgumentParser(description='AI vs éAI å†…å®¹å¯¹æ¯”åˆ†æ')
    parser.add_argument('--ai', required=True, help='AI å†…å®¹æ•°æ®æ–‡ä»¶')
    parser.add_argument('--non-ai', required=True, help='é AI å†…å®¹æ•°æ®æ–‡ä»¶')
    parser.add_argument('--output', default='output/reports', help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    print("="*70)
    print(" AI vs éAI å†…å®¹å¯¹æ¯”åˆ†æ")
    print("="*70)

    # è¯»å–æ•°æ®
    print(f"\nğŸ“Š åŠ è½½æ•°æ®...")
    try:
        df_ai = pd.read_csv(args.ai)
        print(f"  AI å†…å®¹: {len(df_ai)} æ¡è¯„è®º")
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ° AI å†…å®¹æ–‡ä»¶: {args.ai}")
        return 1

    try:
        df_non_ai = pd.read_csv(args.non_ai)
        print(f"  é AI å†…å®¹: {len(df_non_ai)} æ¡è¯„è®º")
    except FileNotFoundError:
        print(f"âŒ æ‰¾ä¸åˆ°é AI å†…å®¹æ–‡ä»¶: {args.non_ai}")
        return 1

    # è®¡ç®—ç»Ÿè®¡æ•°æ®
    print(f"\nğŸ”¬ è¿›è¡Œç»Ÿè®¡åˆ†æ...")
    results = calculate_statistics(df_ai, df_non_ai)

    # ç”ŸæˆæŠ¥å‘Š
    print(f"\nğŸ“ ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
    report_text = generate_report(results, df_ai, df_non_ai)

    # ä¿å­˜æŠ¥å‘Š
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = output_dir / f"ai_vs_nonai_comparison_{timestamp}.txt"

    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report_text)

    # ä¿å­˜ç»Ÿè®¡æ•°æ®ï¼ˆJSONï¼‰
    import json
    stats_path = output_dir / f"ai_vs_nonai_stats_{timestamp}.json"
    with open(stats_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… åˆ†æå®Œæˆï¼")
    print(f"\nğŸ“„ æŠ¥å‘Šå·²ä¿å­˜:")
    print(f"  æ–‡æœ¬æŠ¥å‘Š: {report_path}")
    print(f"  ç»Ÿè®¡æ•°æ®: {stats_path}")

    # æ˜¾ç¤ºæŠ¥å‘Šé¢„è§ˆ
    print("\n" + "="*70)
    print("æŠ¥å‘Šé¢„è§ˆ:")
    print("="*70)
    print(report_text)

    return 0


if __name__ == '__main__':
    sys.exit(main())
