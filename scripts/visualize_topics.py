#!/usr/bin/env python3
"""
ä¸»é¢˜å»ºæ¨¡å¯è§†åŒ–è„šæœ¬

ç”Ÿæˆä¸»é¢˜å»ºæ¨¡çš„è¯¦ç»†å¯è§†åŒ–å›¾è¡¨

Usage:
    python scripts/visualize_topics.py \
        --input data/processed/comments_sentiment_topics.csv \
        --output output/figures
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter

# è®¾ç½®ä¸­æ–‡å­—ä½“ï¼ˆå¦‚æœå¯ç”¨ï¼‰
try:
    plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
except:
    pass


def load_data(input_file: str) -> pd.DataFrame:
    """åŠ è½½æ•°æ®"""
    print(f"\nğŸ“Š åŠ è½½æ•°æ®: {input_file}")
    df = pd.read_csv(input_file)
    print(f"  æ€»è¯„è®ºæ•°: {len(df)}")

    if 'topic' in df.columns:
        valid_topics = df[df['topic'] >= 0]
        print(f"  æœ‰æ•ˆä¸»é¢˜: {len(valid_topics)}")

    return df


def visualize_topic_distribution(df: pd.DataFrame, output_dir: Path):
    """ä¸»é¢˜åˆ†å¸ƒå¯è§†åŒ–"""
    print(f"\nğŸ“Š ç”Ÿæˆä¸»é¢˜åˆ†å¸ƒå›¾...")

    if 'topic' not in df.columns:
        print("  âš ï¸  æœªæ‰¾åˆ°ä¸»é¢˜å­—æ®µ")
        return

    # è¿‡æ»¤æœ‰æ•ˆä¸»é¢˜
    df_topics = df[df['topic'] >= 0].copy()

    if len(df_topics) == 0:
        print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„ä¸»é¢˜æ•°æ®")
        return

    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. ä¸»é¢˜åˆ†å¸ƒé¥¼å›¾
    topic_counts = df_topics['topic'].value_counts().sort_index()
    colors = plt.cm.Set3(range(len(topic_counts)))

    axes[0, 0].pie(topic_counts.values, labels=[f'Topic {i}' for i in topic_counts.index],
                   autopct='%1.1f%%', colors=colors, startangle=90)
    axes[0, 0].set_title('Topic Distribution', fontsize=14, fontweight='bold')

    # 2. ä¸»é¢˜åˆ†å¸ƒæŸ±çŠ¶å›¾
    axes[0, 1].bar(topic_counts.index, topic_counts.values, color=colors, alpha=0.8)
    axes[0, 1].set_xlabel('Topic ID', fontsize=12)
    axes[0, 1].set_ylabel('Number of Comments', fontsize=12)
    axes[0, 1].set_title('Topic Distribution (Bar Chart)', fontsize=14, fontweight='bold')
    axes[0, 1].grid(True, alpha=0.3, axis='y')

    # 3. ä¸»é¢˜-æƒ…æ„Ÿå…³ç³»
    if 'sentiment' in df_topics.columns:
        sentiment_by_topic = pd.crosstab(df_topics['topic'], df_topics['sentiment'], normalize='index') * 100

        sentiment_by_topic.plot(kind='bar', stacked=True, ax=axes[1, 0],
                                color=['#f44336', '#9e9e9e', '#4caf50'], alpha=0.8)
        axes[1, 0].set_xlabel('Topic ID', fontsize=12)
        axes[1, 0].set_ylabel('Percentage (%)', fontsize=12)
        axes[1, 0].set_title('Sentiment Distribution by Topic', fontsize=14, fontweight='bold')
        axes[1, 0].legend(title='Sentiment', labels=['Negative', 'Neutral', 'Positive'])
        axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=0)
        axes[1, 0].grid(True, alpha=0.3, axis='y')

    # 4. ä¸»é¢˜å¹³å‡ç‚¹èµæ•°
    if 'like_count' in df_topics.columns:
        avg_likes_by_topic = df_topics.groupby('topic')['like_count'].mean()

        axes[1, 1].bar(avg_likes_by_topic.index, avg_likes_by_topic.values,
                       color=colors, alpha=0.8)
        axes[1, 1].set_xlabel('Topic ID', fontsize=12)
        axes[1, 1].set_ylabel('Average Likes', fontsize=12)
        axes[1, 1].set_title('Average Likes by Topic', fontsize=14, fontweight='bold')
        axes[1, 1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    output_file = output_dir / 'topic_analysis_comprehensive.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")


def visualize_topic_wordclouds(df: pd.DataFrame, output_dir: Path):
    """ä¸»é¢˜è¯äº‘ï¼ˆå¦‚æœæœ‰æ–‡æœ¬æ•°æ®ï¼‰"""
    print(f"\nâ˜ï¸  ç”Ÿæˆä¸»é¢˜å…³é”®è¯åˆ†æ...")

    if 'topic' not in df.columns or 'text' not in df.columns:
        print("  âš ï¸  ç¼ºå°‘å¿…è¦å­—æ®µ")
        return

    # è¿‡æ»¤æœ‰æ•ˆä¸»é¢˜
    df_topics = df[df['topic'] >= 0].copy()

    if len(df_topics) == 0:
        print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„ä¸»é¢˜æ•°æ®")
        return

    # åˆ†ææ¯ä¸ªä¸»é¢˜çš„å¸¸è§è¯ï¼ˆç®€åŒ–ç‰ˆï¼‰
    topics = sorted(df_topics['topic'].unique())

    fig, axes = plt.subplots(len(topics), 1, figsize=(14, 4 * len(topics)))
    if len(topics) == 1:
        axes = [axes]

    for idx, topic_id in enumerate(topics):
        topic_texts = df_topics[df_topics['topic'] == topic_id]['text'].tolist()

        # ç®€å•çš„è¯é¢‘ç»Ÿè®¡ï¼ˆåˆ†å‰²å¹¶è®¡æ•°ï¼‰
        all_words = []
        for text in topic_texts:
            words = str(text).lower().split()
            all_words.extend([w for w in words if len(w) > 3])  # è¿‡æ»¤çŸ­è¯

        word_freq = Counter(all_words).most_common(15)

        if word_freq:
            words, counts = zip(*word_freq)
            axes[idx].barh(range(len(words)), counts, color=plt.cm.Set3(idx), alpha=0.8)
            axes[idx].set_yticks(range(len(words)))
            axes[idx].set_yticklabels(words)
            axes[idx].set_xlabel('Frequency', fontsize=11)
            axes[idx].set_title(f'Topic {topic_id} - Top 15 Words', fontsize=12, fontweight='bold')
            axes[idx].invert_yaxis()
            axes[idx].grid(True, alpha=0.3, axis='x')

    plt.tight_layout()
    output_file = output_dir / 'topic_keywords.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")


def visualize_topic_engagement(df: pd.DataFrame, output_dir: Path):
    """ä¸»é¢˜äº’åŠ¨åˆ†æ"""
    print(f"\nğŸ’¬ ç”Ÿæˆä¸»é¢˜äº’åŠ¨åˆ†æå›¾...")

    if 'topic' not in df.columns or 'like_count' not in df.columns:
        print("  âš ï¸  ç¼ºå°‘å¿…è¦å­—æ®µ")
        return

    # è¿‡æ»¤æœ‰æ•ˆä¸»é¢˜
    df_topics = df[df['topic'] >= 0].copy()

    if len(df_topics) == 0:
        print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„ä¸»é¢˜æ•°æ®")
        return

    fig, axes = plt.subplots(1, 2, figsize=(16, 6))

    # 1. ä¸»é¢˜ç‚¹èµç®±çº¿å›¾
    topics = sorted(df_topics['topic'].unique())
    like_data = [df_topics[df_topics['topic'] == t]['like_count'].values for t in topics]

    bp = axes[0].boxplot(like_data, labels=[f'Topic {t}' for t in topics],
                         patch_artist=True, showmeans=True)

    colors = plt.cm.Set3(range(len(topics)))
    for patch, color in zip(bp['boxes'], colors):
        patch.set_facecolor(color)
        patch.set_alpha(0.6)

    axes[0].set_xlabel('Topic', fontsize=12)
    axes[0].set_ylabel('Likes', fontsize=12)
    axes[0].set_title('Likes Distribution by Topic (Box Plot)', fontsize=14, fontweight='bold')
    axes[0].grid(True, alpha=0.3, axis='y')

    # 2. ä¸»é¢˜è¯„è®ºé•¿åº¦å¯¹æ¯”
    if 'text_length' in df_topics.columns:
        avg_length_by_topic = df_topics.groupby('topic')['text_length'].mean()

        axes[1].bar(avg_length_by_topic.index, avg_length_by_topic.values,
                    color=colors, alpha=0.8)
        axes[1].set_xlabel('Topic ID', fontsize=12)
        axes[1].set_ylabel('Average Comment Length (chars)', fontsize=12)
        axes[1].set_title('Average Comment Length by Topic', fontsize=14, fontweight='bold')
        axes[1].grid(True, alpha=0.3, axis='y')

    plt.tight_layout()
    output_file = output_dir / 'topic_engagement.png'
    plt.savefig(output_file, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"  âœ“ ä¿å­˜: {output_file}")


def generate_topic_report(df: pd.DataFrame, output_dir: Path):
    """ç”Ÿæˆä¸»é¢˜åˆ†ææŠ¥å‘Š"""
    print(f"\nğŸ“ ç”Ÿæˆä¸»é¢˜åˆ†ææŠ¥å‘Š...")

    if 'topic' not in df.columns:
        print("  âš ï¸  æœªæ‰¾åˆ°ä¸»é¢˜å­—æ®µ")
        return

    df_topics = df[df['topic'] >= 0].copy()

    if len(df_topics) == 0:
        print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„ä¸»é¢˜æ•°æ®")
        return

    report = []

    report.append("=" * 70)
    report.append("ä¸»é¢˜å»ºæ¨¡åˆ†ææŠ¥å‘Š")
    report.append("YouTube Shorts Comments Topic Analysis")
    report.append("=" * 70)
    report.append(f"\nç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"åˆ†æè¯„è®ºæ•°: {len(df_topics):,}")
    report.append("")

    # 1. ä¸»é¢˜åˆ†å¸ƒ
    report.append("=" * 70)
    report.append("1. ä¸»é¢˜åˆ†å¸ƒ (Topic Distribution)")
    report.append("=" * 70)
    report.append("")

    topic_counts = df_topics['topic'].value_counts().sort_index()

    for topic_id, count in topic_counts.items():
        pct = count / len(df_topics) * 100
        report.append(f"Topic {topic_id}:")
        report.append(f"  è¯„è®ºæ•°: {count:,} ({pct:.1f}%)")

        # æƒ…æ„Ÿåˆ†å¸ƒ
        if 'sentiment' in df_topics.columns:
            topic_sentiments = df_topics[df_topics['topic'] == topic_id]['sentiment'].value_counts()
            for sent, sent_count in topic_sentiments.items():
                sent_pct = sent_count / count * 100
                report.append(f"    {sent}: {sent_count} ({sent_pct:.1f}%)")

        # äº’åŠ¨æ•°æ®
        if 'like_count' in df_topics.columns:
            topic_likes = df_topics[df_topics['topic'] == topic_id]['like_count']
            report.append(f"  å¹³å‡ç‚¹èµ: {topic_likes.mean():.2f}")
            report.append(f"  ä¸­ä½æ•°: {topic_likes.median():.0f}")

        report.append("")

    # 2. ä¸»é¢˜å…³é”®ç‰¹å¾
    report.append("=" * 70)
    report.append("2. ä¸»é¢˜å…³é”®ç‰¹å¾ (Topic Characteristics)")
    report.append("=" * 70)
    report.append("")

    # æœ€å—æ¬¢è¿ä¸»é¢˜ï¼ˆå¹³å‡ç‚¹èµæœ€é«˜ï¼‰
    if 'like_count' in df_topics.columns:
        avg_likes = df_topics.groupby('topic')['like_count'].mean().sort_values(ascending=False)
        report.append("æœ€å—æ¬¢è¿ä¸»é¢˜ï¼ˆæŒ‰å¹³å‡ç‚¹èµï¼‰:")
        for topic_id, likes in avg_likes.head(3).items():
            report.append(f"  Topic {topic_id}: {likes:.2f} å¹³å‡ç‚¹èµ")
        report.append("")

    # æœ€ç§¯æä¸»é¢˜
    if 'sentiment' in df_topics.columns:
        positive_ratio = df_topics[df_topics['sentiment'] == 'positive'].groupby('topic').size() / df_topics.groupby('topic').size()
        positive_ratio = positive_ratio.sort_values(ascending=False)
        report.append("æœ€ç§¯æä¸»é¢˜ï¼ˆæŒ‰ç§¯ææƒ…æ„Ÿæ¯”ä¾‹ï¼‰:")
        for topic_id, ratio in positive_ratio.head(3).items():
            report.append(f"  Topic {topic_id}: {ratio*100:.1f}% ç§¯æ")
        report.append("")

    # æœ€é•¿è¯„è®ºä¸»é¢˜
    if 'text_length' in df_topics.columns:
        avg_length = df_topics.groupby('topic')['text_length'].mean().sort_values(ascending=False)
        report.append("è¯„è®ºæœ€é•¿ä¸»é¢˜ï¼ˆæŒ‰å¹³å‡é•¿åº¦ï¼‰:")
        for topic_id, length in avg_length.head(3).items():
            report.append(f"  Topic {topic_id}: {length:.0f} å­—ç¬¦")
        report.append("")

    report.append("=" * 70)
    report.append("æŠ¥å‘Šç»“æŸ")
    report.append("=" * 70)

    # ä¿å­˜æŠ¥å‘Š
    report_text = '\n'.join(report)
    report_file = output_dir / 'topic_analysis_report.txt'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"  âœ“ ä¿å­˜: {report_file}")

    return report_text


def main():
    parser = argparse.ArgumentParser(description='ä¸»é¢˜å»ºæ¨¡å¯è§†åŒ–')
    parser.add_argument('--input', required=True, help='è¾“å…¥ CSV æ–‡ä»¶')
    parser.add_argument('--output', default='output/figures', help='è¾“å‡ºç›®å½•')

    args = parser.parse_args()

    print("=" * 70)
    print(" ä¸»é¢˜å»ºæ¨¡å¯è§†åŒ–å·¥å…·")
    print("=" * 70)

    # åŠ è½½æ•°æ®
    df = load_data(args.input)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # ç”Ÿæˆå„ç±»å¯è§†åŒ–
    visualize_topic_distribution(df, output_dir)
    visualize_topic_wordclouds(df, output_dir)
    visualize_topic_engagement(df, output_dir)
    generate_topic_report(df, output_dir)

    print(f"\nâœ… ä¸»é¢˜å¯è§†åŒ–å®Œæˆï¼")
    print(f"\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
    print(f"  - topic_analysis_comprehensive.png (4å­å›¾)")
    print(f"  - topic_keywords.png (å…³é”®è¯åˆ†æ)")
    print(f"  - topic_engagement.png (äº’åŠ¨åˆ†æ)")
    print(f"  - topic_analysis_report.txt (è¯¦ç»†æŠ¥å‘Š)")
    print()

    return 0


if __name__ == '__main__':
    sys.exit(main())
