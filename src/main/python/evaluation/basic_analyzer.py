#!/usr/bin/env python3
"""
åŸºç¡€æ•°æ®åˆ†æ - æŸ¥çœ‹é¢„å¤„ç†åçš„æ•°æ®

Usage:
    python analyze_basic.py data/processed/comments.csv
"""

import sys
import pandas as pd
from pathlib import Path

if len(sys.argv) < 2:
    print("ç”¨æ³•: python analyze_basic.py <comments.csv>")
    sys.exit(1)

file_path = sys.argv[1]

# è¯»å–æ•°æ®
print("ğŸ“‚ åŠ è½½æ•°æ®...")
df = pd.read_csv(file_path)

print("\n" + "="*70)
print(f" æ•°æ®åˆ†æï¼š{Path(file_path).name}")
print("="*70)

# åŸºæœ¬ä¿¡æ¯
print(f"\nğŸ“Š æ•°æ®ç»´åº¦ï¼š")
print(f"  è¡Œæ•°ï¼š{len(df)}")
print(f"  åˆ—æ•°ï¼š{len(df.columns)}")

print(f"\nğŸ“‹ åˆ—åï¼š")
for col in df.columns:
    print(f"  - {col}")

# ç»Ÿè®¡ä¿¡æ¯
print(f"\nğŸ“ˆ æ–‡æœ¬ç»Ÿè®¡ï¼š")
if 'text_length' in df.columns:
    print(f"  å¹³å‡æ–‡æœ¬é•¿åº¦ï¼š{df['text_length'].mean():.1f} å­—ç¬¦")
    print(f"  ä¸­ä½æ•°ï¼š{df['text_length'].median():.0f} å­—ç¬¦")
    print(f"  æœ€çŸ­ï¼š{df['text_length'].min()}")
    print(f"  æœ€é•¿ï¼š{df['text_length'].max()}")

if 'word_count' in df.columns:
    print(f"\n  å¹³å‡è¯æ•°ï¼š{df['word_count'].mean():.1f}")
    print(f"  ä¸­ä½æ•°ï¼š{df['word_count'].median():.0f}")

# äº’åŠ¨ç»Ÿè®¡
print(f"\nğŸ‘ äº’åŠ¨ç»Ÿè®¡ï¼š")
if 'like_count' in df.columns:
    print(f"  æ€»ç‚¹èµæ•°ï¼š{df['like_count'].sum()}")
    print(f"  å¹³å‡ç‚¹èµï¼š{df['like_count'].mean():.1f}")
    print(f"  æœ€é«˜ç‚¹èµï¼š{df['like_count'].max()}")

    # çƒ­é—¨è¯„è®º
    top_comments = df.nlargest(3, 'like_count')
    print(f"\nğŸ”¥ æœ€çƒ­é—¨è¯„è®ºï¼ˆTop 3ï¼‰ï¼š")
    for i, (idx, row) in enumerate(top_comments.iterrows(), 1):
        text = row['text_clean'][:80] if pd.notna(row.get('text_clean')) else row['text'][:80]
        print(f"\n  {i}. ğŸ‘ {row['like_count']} èµ")
        print(f"     {text}...")

# æ—¶é—´åˆ†å¸ƒ
if 'published_datetime' in df.columns:
    print(f"\nğŸ“… æ—¶é—´åˆ†å¸ƒï¼š")
    df['published_datetime'] = pd.to_datetime(df['published_datetime'])
    print(f"  æ—¶é—´è·¨åº¦ï¼š{df['published_datetime'].min()} åˆ° {df['published_datetime'].max()}")

    if 'published_date' in df.columns:
        date_counts = df['published_date'].value_counts().head(5)
        print(f"\n  å‘å¸ƒæœ€å¤šçš„æ—¥æœŸï¼š")
        for date, count in date_counts.items():
            print(f"    {date}: {count} æ¡è¯„è®º")

# ä½œè€…åˆ†æ
if 'author' in df.columns:
    print(f"\nğŸ‘¥ ä½œè€…åˆ†æï¼š")
    print(f"  ç‹¬ç«‹ä½œè€…ï¼š{df['author'].nunique()}")

    top_authors = df['author'].value_counts().head(5)
    print(f"\n  æœ€æ´»è·ƒä½œè€…ï¼š")
    for author, count in top_authors.items():
        print(f"    {author}: {count} æ¡è¯„è®º")

# è§†é¢‘åˆ†å¸ƒ
if 'video_id' in df.columns:
    print(f"\nğŸ¬ è§†é¢‘åˆ†æï¼š")
    print(f"  æ¶‰åŠè§†é¢‘ï¼š{df['video_id'].nunique()}")

    video_counts = df['video_id'].value_counts().head(5)
    print(f"\n  è¯„è®ºæœ€å¤šçš„è§†é¢‘ï¼š")
    for video_id, count in video_counts.items():
        print(f"    {video_id}: {count} æ¡è¯„è®º")

# ä¿å­˜å¿«é€Ÿç»Ÿè®¡
summary = {
    'total_comments': len(df),
    'unique_authors': df['author'].nunique() if 'author' in df.columns else 0,
    'unique_videos': df['video_id'].nunique() if 'video_id' in df.columns else 0,
    'avg_text_length': df['text_length'].mean() if 'text_length' in df.columns else 0,
    'avg_word_count': df['word_count'].mean() if 'word_count' in df.columns else 0,
    'total_likes': df['like_count'].sum() if 'like_count' in df.columns else 0,
}

print("\n" + "="*70)
print("âœ… æ•°æ®åˆ†æå®Œæˆ")
print("="*70)

print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®ï¼š")
print(f"  1. è¿è¡Œæƒ…æ„Ÿåˆ†æè¯†åˆ«æ­£é¢/è´Ÿé¢è¯„è®º")
print(f"  2. è¿›è¡Œä¸»é¢˜å»ºæ¨¡å‘ç°è®¨è®ºè¯é¢˜")
print(f"  3. ä½¿ç”¨ pandas/Excel æ·±å…¥æ¢ç´¢æ•°æ®")
print()
