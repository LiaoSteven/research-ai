#!/usr/bin/env python3
"""
å¤§è§„æ¨¡æ—¶é—´åºåˆ—æ•°æ®é‡‡é›†å™¨ (2022-2025)

é‡‡é›†ç­–ç•¥ï¼š
1. æ—¶é—´åˆ†å±‚æŠ½æ ·ï¼šæŒ‰å­£åº¦å‡åŒ€åˆ†å¸ƒï¼ˆ2022Q1 - 2025Q4ï¼Œå…±16ä¸ªå­£åº¦ï¼‰
2. AI/éAIå¹³è¡¡ï¼š50% AIç”Ÿæˆå†…å®¹ vs 50% ä¼ ç»Ÿå†…å®¹
3. å…³é”®æ—¶é—´èŠ‚ç‚¹é‡ç‚¹é‡‡æ ·ï¼š
   - 2022Q4: ChatGPT å‘å¸ƒï¼ˆ2022å¹´11æœˆï¼‰
   - 2023Q1-Q2: AI å·¥å…·çˆ†å‘æœŸ
   - 2024-2025: AI å†…å®¹æˆç†ŸæœŸ

ç›®æ ‡ï¼š100,000 æ¡è¯„è®º
- æ¯å­£åº¦ï¼š~6,250 æ¡è¯„è®º
- æ¯å­£åº¦ AI å†…å®¹ï¼š~3,125 æ¡
- æ¯å­£åº¦é AI å†…å®¹ï¼š~3,125 æ¡

ä½¿ç”¨æ–¹æ³•ï¼š
    python large_scale_temporal_collector.py --total 100000 --start-date 2022-01-01 --end-date 2025-10-31
"""

import sys
from pathlib import Path
import argparse
import os
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import random

# æ·»åŠ  src åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# åŠ è½½ .env æ–‡ä»¶
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# å¯¼å…¥æ¨¡å—
from src.main.python.services.youtube_collector import YouTubeCollector
from src.main.python.services.ai_comparison_collector import ComparisonCollector


class TemporalSamplingStrategy:
    """æ—¶é—´åˆ†å±‚é‡‡æ ·ç­–ç•¥"""

    # å…³é”®æ—¶é—´èŠ‚ç‚¹ï¼ˆAI æŠ€æœ¯å‘å±•é‡Œç¨‹ç¢‘ï¼‰
    KEY_MILESTONES = {
        '2022-11-30': 'ChatGPT Launch',
        '2023-03-14': 'GPT-4 Release',
        '2023-05-10': 'Google Bard Launch',
        '2024-02-15': 'Sora Announcement',
        '2024-05-13': 'GPT-4o Release'
    }

    def __init__(self, start_date: str, end_date: str, total_comments: int):
        """
        åˆå§‹åŒ–é‡‡æ ·ç­–ç•¥

        Args:
            start_date: èµ·å§‹æ—¥æœŸ (YYYY-MM-DD)
            end_date: ç»“æŸæ—¥æœŸ (YYYY-MM-DD)
            total_comments: ç›®æ ‡æ€»è¯„è®ºæ•°
        """
        self.start_date = datetime.strptime(start_date, '%Y-%m-%d')
        self.end_date = datetime.strptime(end_date, '%Y-%m-%d')
        self.total_comments = total_comments

        # ç”Ÿæˆå­£åº¦åˆ†å¸ƒ
        self.quarters = self._generate_quarters()
        self.sampling_plan = self._create_sampling_plan()

    def _generate_quarters(self) -> List[Dict]:
        """ç”Ÿæˆæ‰€æœ‰å­£åº¦"""
        quarters = []
        current = self.start_date

        while current <= self.end_date:
            year = current.year
            month = current.month
            quarter = (month - 1) // 3 + 1

            # è®¡ç®—å­£åº¦çš„èµ·æ­¢æ—¥æœŸ
            q_start = datetime(year, (quarter-1)*3 + 1, 1)
            if quarter < 4:
                q_end = datetime(year, quarter*3 + 1, 1) - timedelta(days=1)
            else:
                q_end = datetime(year, 12, 31)

            # ç¡®ä¿åœ¨é‡‡æ ·èŒƒå›´å†…
            q_start = max(q_start, self.start_date)
            q_end = min(q_end, self.end_date)

            quarter_key = f"{year}Q{quarter}"
            quarters.append({
                'key': quarter_key,
                'year': year,
                'quarter': quarter,
                'start': q_start,
                'end': q_end,
                'is_milestone': self._is_milestone_quarter(q_start, q_end)
            })

            # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå­£åº¦
            if quarter < 4:
                current = datetime(year, quarter*3 + 1, 1)
            else:
                current = datetime(year + 1, 1, 1)

        return quarters

    def _is_milestone_quarter(self, q_start: datetime, q_end: datetime) -> bool:
        """æ£€æŸ¥å­£åº¦æ˜¯å¦åŒ…å«å…³é”®é‡Œç¨‹ç¢‘"""
        for milestone_date in self.KEY_MILESTONES.keys():
            m_date = datetime.strptime(milestone_date, '%Y-%m-%d')
            if q_start <= m_date <= q_end:
                return True
        return False

    def _create_sampling_plan(self) -> List[Dict]:
        """åˆ›å»ºé‡‡æ ·è®¡åˆ’"""
        num_quarters = len(self.quarters)
        base_per_quarter = self.total_comments // num_quarters
        remainder = self.total_comments % num_quarters

        plan = []
        for idx, quarter_info in enumerate(self.quarters):
            # ä¸ºé‡Œç¨‹ç¢‘å­£åº¦åˆ†é…æ›´å¤šæ ·æœ¬
            if quarter_info['is_milestone']:
                allocation = int(base_per_quarter * 1.2)  # å¢åŠ  20%
            else:
                allocation = base_per_quarter

            # åˆ†é…å‰©ä½™æ ·æœ¬
            if idx < remainder:
                allocation += 1

            # AI vs éAI åˆ†é… (50/50)
            ai_allocation = allocation // 2
            non_ai_allocation = allocation - ai_allocation

            plan.append({
                **quarter_info,
                'total_target': allocation,
                'ai_target': ai_allocation,
                'non_ai_target': non_ai_allocation,
                'collected_ai': 0,
                'collected_non_ai': 0
            })

        return plan

    def get_sampling_plan(self) -> List[Dict]:
        """è·å–å®Œæ•´é‡‡æ ·è®¡åˆ’"""
        return self.sampling_plan

    def print_plan(self):
        """æ‰“å°é‡‡æ ·è®¡åˆ’"""
        print("\n" + "="*80)
        print(" æ—¶é—´åˆ†å±‚é‡‡æ ·è®¡åˆ’ (Temporal Stratified Sampling Plan)")
        print("="*80)
        print(f"\nğŸ“… æ—¶é—´èŒƒå›´: {self.start_date.date()} è‡³ {self.end_date.date()}")
        print(f"ğŸ¯ ç›®æ ‡è¯„è®ºæ•°: {self.total_comments:,} æ¡")
        print(f"ğŸ“Š å­£åº¦æ•°é‡: {len(self.quarters)}")
        print(f"âš–ï¸ AI/éAI æ¯”ä¾‹: 50% / 50%")

        print("\n" + "-"*80)
        print(f"{'å­£åº¦':<10} {'æ—¥æœŸèŒƒå›´':<25} {'æ€»æ•°':<8} {'AI':<8} {'éAI':<8} {'é‡Œç¨‹ç¢‘':<10}")
        print("-"*80)

        total_ai = 0
        total_non_ai = 0

        for q in self.sampling_plan:
            milestone_mark = "â­" if q['is_milestone'] else ""
            date_range = f"{q['start'].date()} ~ {q['end'].date()}"
            print(f"{q['key']:<10} {date_range:<25} {q['total_target']:<8} "
                  f"{q['ai_target']:<8} {q['non_ai_target']:<8} {milestone_mark:<10}")
            total_ai += q['ai_target']
            total_non_ai += q['non_ai_target']

        print("-"*80)
        print(f"{'æ€»è®¡':<10} {'':<25} {total_ai + total_non_ai:<8} "
              f"{total_ai:<8} {total_non_ai:<8}")
        print("="*80)

        # æ˜¾ç¤ºå…³é”®é‡Œç¨‹ç¢‘
        print("\nâ­ å…³é”®æ—¶é—´èŠ‚ç‚¹:")
        for date, event in self.KEY_MILESTONES.items():
            if self.start_date <= datetime.strptime(date, '%Y-%m-%d') <= self.end_date:
                print(f"   â€¢ {date}: {event}")
        print()


class LargeScaleTemporalCollector:
    """å¤§è§„æ¨¡æ—¶é—´åºåˆ—é‡‡é›†å™¨"""

    # æ‰©å±•çš„æœç´¢å…³é”®è¯
    AI_SEARCH_QUERIES = [
        # AI å·¥å…·ç›¸å…³
        'AI generated shorts', 'AI art shorts', 'AI animation shorts',
        'midjourney shorts', 'stable diffusion shorts', 'dalle shorts',
        'AI video shorts', 'generative AI shorts', 'AI created shorts',

        # AI æŠ€æœ¯è®¨è®º
        'ChatGPT shorts', 'GPT shorts', 'AI tutorial shorts',
        'machine learning shorts', 'AI demo shorts',

        # å¹´ä»½ç‰¹å®šæœç´¢ (ç”¨äºæ—¶é—´è¿‡æ»¤)
        'AI shorts 2022', 'AI shorts 2023', 'AI shorts 2024', 'AI shorts 2025',
    ]

    NON_AI_SEARCH_QUERIES = [
        # ä¼ ç»Ÿåˆ›ä½œ
        'handmade shorts', 'traditional art shorts', 'hand drawn shorts',
        'real footage shorts', 'filmed shorts', 'photography shorts',

        # äººå·¥åˆ›ä½œå†…å®¹
        'vlog shorts', 'cooking shorts', 'DIY shorts', 'tutorial shorts',
        'gaming shorts', 'music shorts', 'dance shorts', 'sports shorts',

        # å¹´ä»½ç‰¹å®šæœç´¢
        'vlog 2022', 'vlog 2023', 'vlog 2024', 'vlog 2025',
        'cooking 2022', 'cooking 2023', 'cooking 2024', 'cooking 2025',
    ]

    def __init__(self, api_key: str, sampling_strategy: TemporalSamplingStrategy):
        """
        åˆå§‹åŒ–é‡‡é›†å™¨

        Args:
            api_key: YouTube API å¯†é’¥
            sampling_strategy: é‡‡æ ·ç­–ç•¥
        """
        self.api_key = api_key
        self.strategy = sampling_strategy
        self.comparison_collector = ComparisonCollector(api_key)
        self.youtube = self.comparison_collector.youtube

        # è¿›åº¦è·Ÿè¸ª
        self.progress = {
            'total_collected': 0,
            'ai_collected': 0,
            'non_ai_collected': 0,
            'quarters_completed': 0
        }

    def search_videos_by_date(
        self,
        queries: List[str],
        after_date: datetime,
        before_date: datetime,
        max_results: int = 50,
        video_type: str = 'ai'
    ) -> List[str]:
        """
        æŒ‰æ—¥æœŸèŒƒå›´æœç´¢è§†é¢‘

        Args:
            queries: æœç´¢å…³é”®è¯åˆ—è¡¨
            after_date: èµ·å§‹æ—¥æœŸ
            before_date: ç»“æŸæ—¥æœŸ
            max_results: æœ€å¤šè¿”å›è§†é¢‘æ•°
            video_type: 'ai' æˆ– 'non_ai'

        Returns:
            è§†é¢‘ ID åˆ—è¡¨
        """
        video_ids = []
        found_videos = set()

        # RFC 3339 æ ¼å¼çš„æ—¥æœŸæ—¶é—´
        published_after = after_date.strftime('%Y-%m-%dT%H:%M:%SZ')
        published_before = before_date.strftime('%Y-%m-%dT%H:%M:%SZ')

        print(f"\nğŸ” æœç´¢ {video_type.upper()} è§†é¢‘...")
        print(f"   æ—¶é—´èŒƒå›´: {after_date.date()} ~ {before_date.date()}")

        for query in queries:
            if len(video_ids) >= max_results:
                break

            try:
                search_params = {
                    'part': 'id,snippet',
                    'type': 'video',
                    'q': query,
                    'videoDuration': 'short',
                    'publishedAfter': published_after,
                    'publishedBefore': published_before,
                    'maxResults': min(50, max_results - len(video_ids)),
                    'order': 'relevance',
                    'regionCode': 'US'
                }

                request = self.youtube.search().list(**search_params)
                response = request.execute()

                for item in response.get('items', []):
                    if 'videoId' in item['id']:
                        video_id = item['id']['videoId']
                        if video_id not in found_videos:
                            found_videos.add(video_id)
                            video_ids.append(video_id)

                time.sleep(1)  # API é™æµ

            except Exception as e:
                print(f"   âœ— æœç´¢é”™è¯¯: {e}")
                continue

        print(f"   âœ“ æ‰¾åˆ° {len(video_ids)} ä¸ªè§†é¢‘")
        return video_ids

    def collect_quarter(self, quarter_plan: Dict) -> Tuple[List, List]:
        """
        é‡‡é›†å•ä¸ªå­£åº¦çš„æ•°æ®

        Args:
            quarter_plan: å­£åº¦é‡‡æ ·è®¡åˆ’

        Returns:
            (ai_comments, non_ai_comments)
        """
        print("\n" + "="*80)
        print(f" é‡‡é›†å­£åº¦: {quarter_plan['key']}")
        print("="*80)
        print(f" æ—¥æœŸ: {quarter_plan['start'].date()} ~ {quarter_plan['end'].date()}")
        print(f" ç›®æ ‡: AI {quarter_plan['ai_target']} æ¡ + éAI {quarter_plan['non_ai_target']} æ¡")
        if quarter_plan['is_milestone']:
            print(" â­ é‡Œç¨‹ç¢‘å­£åº¦ - é‡ç‚¹é‡‡æ ·")
        print("="*80)

        # 1. é‡‡é›† AI å†…å®¹
        print("\n[1/2] é‡‡é›† AI å†…å®¹...")
        ai_videos = self.search_videos_by_date(
            self.AI_SEARCH_QUERIES,
            quarter_plan['start'],
            quarter_plan['end'],
            max_results=quarter_plan['ai_target'] // 20,  # å‡è®¾æ¯è§†é¢‘20æ¡è¯„è®º
            video_type='ai'
        )

        ai_comments, _ = self.comparison_collector.collect_with_detection(
            target_type='ai',
            max_comments=quarter_plan['ai_target'],
            per_video=20,
            region='US',
            verify_threshold=0.3
        )

        # ä¸ºè¯„è®ºæ·»åŠ å­£åº¦æ ‡ç­¾
        for comment in ai_comments:
            comment['quarter'] = quarter_plan['key']
            comment['year'] = quarter_plan['year']
            comment['is_milestone_quarter'] = quarter_plan['is_milestone']

        # 2. é‡‡é›†é AI å†…å®¹
        print("\n[2/2] é‡‡é›†é AI å†…å®¹...")
        non_ai_videos = self.search_videos_by_date(
            self.NON_AI_SEARCH_QUERIES,
            quarter_plan['start'],
            quarter_plan['end'],
            max_results=quarter_plan['non_ai_target'] // 20,
            video_type='non_ai'
        )

        non_ai_comments, _ = self.comparison_collector.collect_with_detection(
            target_type='non_ai',
            max_comments=quarter_plan['non_ai_target'],
            per_video=20,
            region='US',
            verify_threshold=0.3
        )

        # ä¸ºè¯„è®ºæ·»åŠ å­£åº¦æ ‡ç­¾
        for comment in non_ai_comments:
            comment['quarter'] = quarter_plan['key']
            comment['year'] = quarter_plan['year']
            comment['is_milestone_quarter'] = quarter_plan['is_milestone']

        # æ›´æ–°è¿›åº¦
        quarter_plan['collected_ai'] = len(ai_comments)
        quarter_plan['collected_non_ai'] = len(non_ai_comments)
        self.progress['ai_collected'] += len(ai_comments)
        self.progress['non_ai_collected'] += len(non_ai_comments)
        self.progress['total_collected'] += len(ai_comments) + len(non_ai_comments)
        self.progress['quarters_completed'] += 1

        print(f"\nâœ… {quarter_plan['key']} å®Œæˆ:")
        print(f"   AI: {len(ai_comments)} æ¡")
        print(f"   éAI: {len(non_ai_comments)} æ¡")
        print(f"   æ€»è®¡: {len(ai_comments) + len(non_ai_comments)} æ¡")

        return ai_comments, non_ai_comments

    def collect_all(self, output_dir: Path, checkpoint_interval: int = 1) -> Dict:
        """
        é‡‡é›†æ‰€æœ‰æ•°æ®

        Args:
            output_dir: è¾“å‡ºç›®å½•
            checkpoint_interval: æ£€æŸ¥ç‚¹é—´éš”ï¼ˆæ¯Nä¸ªå­£åº¦ä¿å­˜ä¸€æ¬¡ï¼‰

        Returns:
            é‡‡é›†ç»“æœç»Ÿè®¡
        """
        output_dir.mkdir(parents=True, exist_ok=True)

        all_ai_comments = []
        all_non_ai_comments = []
        sampling_plan = self.strategy.get_sampling_plan()

        print("\n" + "="*80)
        print(" å¼€å§‹å¤§è§„æ¨¡æ•°æ®é‡‡é›†")
        print("="*80)

        for idx, quarter_plan in enumerate(sampling_plan, 1):
            print(f"\nè¿›åº¦: [{idx}/{len(sampling_plan)}] å­£åº¦")

            try:
                ai_comments, non_ai_comments = self.collect_quarter(quarter_plan)
                all_ai_comments.extend(ai_comments)
                all_non_ai_comments.extend(non_ai_comments)

                # å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
                if idx % checkpoint_interval == 0:
                    self._save_checkpoint(
                        output_dir,
                        all_ai_comments,
                        all_non_ai_comments,
                        quarter_plan['key']
                    )

                # æ˜¾ç¤ºæ€»ä½“è¿›åº¦
                self._print_progress()

            except Exception as e:
                print(f"\nâŒ å­£åº¦ {quarter_plan['key']} é‡‡é›†å¤±è´¥: {e}")
                continue

        # ä¿å­˜æœ€ç»ˆç»“æœ
        final_result = self._save_final_results(
            output_dir,
            all_ai_comments,
            all_non_ai_comments,
            sampling_plan
        )

        return final_result

    def _save_checkpoint(
        self,
        output_dir: Path,
        ai_comments: List,
        non_ai_comments: List,
        checkpoint_name: str
    ):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        checkpoint_file = output_dir / f'checkpoint_{checkpoint_name}.json'
        checkpoint_data = {
            'timestamp': datetime.now().isoformat(),
            'progress': self.progress,
            'ai_comments_count': len(ai_comments),
            'non_ai_comments_count': len(non_ai_comments),
            'ai_comments': ai_comments,
            'non_ai_comments': non_ai_comments
        }

        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump(checkpoint_data, f, ensure_ascii=False, indent=2)

        print(f"\nğŸ’¾ æ£€æŸ¥ç‚¹å·²ä¿å­˜: {checkpoint_file}")

    def _save_final_results(
        self,
        output_dir: Path,
        ai_comments: List,
        non_ai_comments: List,
        sampling_plan: List[Dict]
    ) -> Dict:
        """ä¿å­˜æœ€ç»ˆç»“æœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ä¿å­˜è¯„è®ºæ•°æ®
        ai_file = output_dir / f'comments_ai_2022-2025_{timestamp}.json'
        non_ai_file = output_dir / f'comments_non_ai_2022-2025_{timestamp}.json'
        all_file = output_dir / f'comments_all_2022-2025_{timestamp}.json'

        with open(ai_file, 'w', encoding='utf-8') as f:
            json.dump(ai_comments, f, ensure_ascii=False, indent=2)

        with open(non_ai_file, 'w', encoding='utf-8') as f:
            json.dump(non_ai_comments, f, ensure_ascii=False, indent=2)

        all_comments = ai_comments + non_ai_comments
        with open(all_file, 'w', encoding='utf-8') as f:
            json.dump(all_comments, f, ensure_ascii=False, indent=2)

        # ä¿å­˜é‡‡æ ·è®¡åˆ’å’Œå…ƒæ•°æ®
        metadata_file = output_dir / f'sampling_metadata_{timestamp}.json'
        metadata = {
            'collection_timestamp': datetime.now().isoformat(),
            'total_comments': len(all_comments),
            'ai_comments': len(ai_comments),
            'non_ai_comments': len(non_ai_comments),
            'quarters_covered': len(sampling_plan),
            'sampling_plan': sampling_plan,
            'progress': self.progress,
            'files': {
                'ai_comments': str(ai_file),
                'non_ai_comments': str(non_ai_file),
                'all_comments': str(all_file)
            }
        }

        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
        self._print_final_report(metadata)

        return metadata

    def _print_progress(self):
        """æ‰“å°å½“å‰è¿›åº¦"""
        total_target = self.strategy.total_comments
        collected = self.progress['total_collected']
        percentage = (collected / total_target * 100) if total_target > 0 else 0

        print(f"\nğŸ“Š æ€»ä½“è¿›åº¦:")
        print(f"   å·²é‡‡é›†: {collected:,} / {total_target:,} ({percentage:.1f}%)")
        print(f"   AI å†…å®¹: {self.progress['ai_collected']:,}")
        print(f"   é AI: {self.progress['non_ai_collected']:,}")
        print(f"   å®Œæˆå­£åº¦: {self.progress['quarters_completed']}/{len(self.strategy.quarters)}")

    def _print_final_report(self, metadata: Dict):
        """æ‰“å°æœ€ç»ˆæŠ¥å‘Š"""
        print("\n" + "="*80)
        print(" é‡‡é›†å®Œæˆï¼")
        print("="*80)
        print(f"\nğŸ“Š é‡‡é›†ç»Ÿè®¡:")
        print(f"   æ€»è¯„è®ºæ•°: {metadata['total_comments']:,}")
        print(f"   AI å†…å®¹: {metadata['ai_comments']:,} ({metadata['ai_comments']/metadata['total_comments']*100:.1f}%)")
        print(f"   é AI: {metadata['non_ai_comments']:,} ({metadata['non_ai_comments']/metadata['total_comments']*100:.1f}%)")
        print(f"   å­£åº¦è¦†ç›–: {metadata['quarters_covered']} ä¸ªå­£åº¦")

        print(f"\nğŸ’¾ æ–‡ä»¶ä¿å­˜:")
        print(f"   AI è¯„è®º: {metadata['files']['ai_comments']}")
        print(f"   é AI è¯„è®º: {metadata['files']['non_ai_comments']}")
        print(f"   å…¨éƒ¨è¯„è®º: {metadata['files']['all_comments']}")

        print(f"\nâœ¨ ä¸‹ä¸€æ­¥:")
        print(f"   1. æ•°æ®é¢„å¤„ç†: python scripts/preprocess_large_scale.py")
        print(f"   2. æƒ…æ„Ÿåˆ†æ: python scripts/run_sentiment_analysis.py")
        print(f"   3. ä¸»é¢˜å»ºæ¨¡: python scripts/run_topic_modeling.py")
        print(f"   4. æ—¶é—´åºåˆ—åˆ†æ: python scripts/run_time_series_analysis.py")
        print(f"   5. AI vs éAI å¯¹æ¯”: python scripts/compare_ai_vs_nonai.py")
        print()


def main():
    parser = argparse.ArgumentParser(
        description='å¤§è§„æ¨¡æ—¶é—´åºåˆ—æ•°æ®é‡‡é›†å™¨ (2022-2025)'
    )
    parser.add_argument('--total', type=int, default=100000,
                       help='ç›®æ ‡æ€»è¯„è®ºæ•° (é»˜è®¤ 100,000)')
    parser.add_argument('--start-date', type=str, default='2022-01-01',
                       help='èµ·å§‹æ—¥æœŸ YYYY-MM-DD (é»˜è®¤ 2022-01-01)')
    parser.add_argument('--end-date', type=str, default='2025-10-31',
                       help='ç»“æŸæ—¥æœŸ YYYY-MM-DD (é»˜è®¤ 2025-10-31)')
    parser.add_argument('--checkpoint-interval', type=int, default=1,
                       help='æ£€æŸ¥ç‚¹ä¿å­˜é—´éš”ï¼ˆå­£åº¦æ•°ï¼Œé»˜è®¤ 1ï¼‰')
    parser.add_argument('--output-dir', type=str, default='data/raw',
                       help='è¾“å‡ºç›®å½• (é»˜è®¤ data/raw)')

    args = parser.parse_args()

    print("\n" + "="*80)
    print(" YouTube Shorts å¤§è§„æ¨¡æ—¶é—´åºåˆ—æ•°æ®é‡‡é›†")
    print(" Large-Scale Temporal Data Collection (2022-2025)")
    print("="*80)

    # æ£€æŸ¥ API key
    api_key = os.getenv('YOUTUBE_API_KEY')
    if not api_key:
        print("\nâŒ é”™è¯¯ï¼šæœªæ‰¾åˆ° YouTube API å¯†é’¥")
        print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½® YOUTUBE_API_KEY")
        return 1

    # åˆ›å»ºé‡‡æ ·ç­–ç•¥
    strategy = TemporalSamplingStrategy(
        start_date=args.start_date,
        end_date=args.end_date,
        total_comments=args.total
    )

    # æ˜¾ç¤ºé‡‡æ ·è®¡åˆ’
    strategy.print_plan()

    # ç¡®è®¤å¼€å§‹
    print("\nâš ï¸ æ³¨æ„:")
    print(f"   â€¢ æ­¤é‡‡é›†å°†æ¶ˆè€—å¤§é‡ YouTube API é…é¢")
    print(f"   â€¢ é¢„è®¡è€—æ—¶: æ•°å°æ—¶åˆ°æ•°å¤©ï¼ˆå–å†³äº API é™æµï¼‰")
    print(f"   â€¢ æ£€æŸ¥ç‚¹å°†æ¯ {args.checkpoint_interval} ä¸ªå­£åº¦ä¿å­˜ä¸€æ¬¡")

    response = input("\næ˜¯å¦å¼€å§‹é‡‡é›†ï¼Ÿ(yes/no): ")
    if response.lower() not in ['yes', 'y']:
        print("å·²å–æ¶ˆ")
        return 0

    # åˆå§‹åŒ–é‡‡é›†å™¨
    try:
        collector = LargeScaleTemporalCollector(
            api_key=api_key,
            sampling_strategy=strategy
        )
        print("\nâœ… YouTube API è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±è´¥: {e}")
        return 1

    # å¼€å§‹é‡‡é›†
    output_dir = Path(args.output_dir)
    try:
        result = collector.collect_all(
            output_dir=output_dir,
            checkpoint_interval=args.checkpoint_interval
        )
        return 0
    except KeyboardInterrupt:
        print("\n\nâš ï¸ ç”¨æˆ·ä¸­æ–­é‡‡é›†")
        print("æ£€æŸ¥ç‚¹æ–‡ä»¶å·²ä¿å­˜ï¼Œå¯ä»¥ç¨åç»§ç»­")
        return 1
    except Exception as e:
        print(f"\nâŒ é‡‡é›†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
