#!/usr/bin/env python3
"""
自然分布采样器 - 不预设AI/非AI比例

采样策略：
1. 按时间均匀分布采样（每季度约6,250条评论）
2. 对每个视频自动检测是否AI生成
3. 自然获得每个季度的真实AI占比
4. AI占比本身就是研究发现，而非预设假设

研究问题：
- AI视频占比如何演变？（数据驱动的发现）
- 观众对AI内容的反应如何变化？
- AI vs 非AI内容的差异是什么？

使用方法：
    python natural_distribution_collector.py --total 100000 --start-date 2022-01-01 --end-date 2025-10-31
"""

import sys
from pathlib import Path
import argparse
import os
import json
import time
from datetime import datetime, timedelta
from typing import List, Dict, Tuple
import random

# 添加 src 到路径
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# 加载 .env 文件
try:
    from dotenv import load_dotenv
    load_dotenv()
except ImportError:
    pass

# 导入模块
from src.main.python.services.youtube_collector import YouTubeCollector


class AIContentDetector:
    """AI内容检测器 - 基于关键词的简单实现"""

    # AI相关关键词（标题、描述、标签）
    AI_KEYWORDS = [
        # 工具名称
        'ai', 'artificial intelligence', 'chatgpt', 'gpt', 'midjourney',
        'stable diffusion', 'dall-e', 'dalle', 'ai generated', 'ai art',
        'ai animation', 'ai video', 'generative ai', 'sora', 'runway',

        # 中文关键词
        'ai生成', 'ai制作', 'ai创作', '人工智能', 'ai绘画', 'ai视频',

        # 描述性词汇
        'generated by ai', 'created with ai', 'made with ai',
        'ai-generated', 'ai-created', 'machine learning', 'neural network',
        'text to image', 'text to video', 'ai model', 'diffusion model'
    ]

    # 排除关键词（假阳性过滤）
    EXCLUDE_KEYWORDS = [
        'against ai', 'anti ai', 'no ai', 'human made', 'real footage',
        'traditional art', 'hand drawn', 'handmade'
    ]

    def __init__(self):
        """初始化检测器"""
        self.ai_keywords_lower = [kw.lower() for kw in self.AI_KEYWORDS]
        self.exclude_keywords_lower = [kw.lower() for kw in self.EXCLUDE_KEYWORDS]

    def detect(self, video_info: Dict) -> Dict:
        """
        检测视频是否AI生成

        Args:
            video_info: 视频信息字典

        Returns:
            {
                'is_ai': bool,
                'confidence': float,
                'matched_keywords': list,
                'detection_source': str
            }
        """
        title = video_info.get('title', '').lower()
        description = video_info.get('description', '').lower()
        tags = ' '.join(video_info.get('tags', [])).lower()

        combined_text = f"{title} {description} {tags}"

        # 检查排除关键词
        for exclude_kw in self.exclude_keywords_lower:
            if exclude_kw in combined_text:
                return {
                    'is_ai': False,
                    'confidence': 0.0,
                    'matched_keywords': [],
                    'detection_source': 'excluded',
                    'reason': f'Matched exclude keyword: {exclude_kw}'
                }

        # 检测AI关键词
        matched_keywords = []
        scores = []

        for keyword in self.ai_keywords_lower:
            if keyword in combined_text:
                matched_keywords.append(keyword)

                # 权重计算
                if keyword in title:
                    scores.append(0.5)  # 标题中出现权重高
                elif keyword in description[:200]:  # 描述前200字符
                    scores.append(0.3)
                elif keyword in tags:
                    scores.append(0.4)
                else:
                    scores.append(0.2)

        # 计算置信度
        if not matched_keywords:
            confidence = 0.0
            is_ai = False
        else:
            # 置信度 = 关键词数量 × 平均权重
            confidence = min(len(matched_keywords) * sum(scores) / len(scores), 1.0)
            is_ai = confidence >= 0.2  # 阈值：0.2

        return {
            'is_ai': is_ai,
            'confidence': round(confidence, 3),
            'matched_keywords': matched_keywords[:5],  # 最多记录5个
            'detection_source': 'keyword_matching',
            'num_matches': len(matched_keywords)
        }


class NaturalDistributionCollector:
    """自然分布采样器 - 不预设AI比例"""

    # 通用搜索关键词（不偏向AI或非AI）
    GENERAL_QUERIES = [
        # 热门短视频类别
        'shorts', 'viral shorts', 'trending shorts',
        'popular shorts', 'funny shorts', 'creative shorts',

        # 内容类型
        'art shorts', 'animation shorts', 'video shorts',
        'tutorial shorts', 'educational shorts', 'entertainment shorts',

        # 年份关键词（用于时间过滤）
        'shorts 2022', 'shorts 2023', 'shorts 2024', 'shorts 2025',

        # 创作相关
        'creative content', 'content creation', 'video creation',
        'digital art', 'visual effects', 'motion graphics'
    ]

    def __init__(self, api_key: str):
        """初始化采集器"""
        self.collector = YouTubeCollector(api_key=api_key)
        self.detector = AIContentDetector()
        self.youtube = self.collector.youtube

        # 统计信息
        self.stats = {
            'total_videos_searched': 0,
            'total_comments_collected': 0,
            'ai_videos': 0,
            'non_ai_videos': 0,
            'detection_failures': 0,
            'quarters_completed': 0
        }

    def search_videos_by_quarter(
        self,
        start_date: datetime,
        end_date: datetime,
        max_videos: int = 200
    ) -> List[str]:
        """
        按季度搜索视频（不偏向任何类型）

        Args:
            start_date: 季度起始日期
            end_date: 季度结束日期
            max_videos: 最多搜索视频数

        Returns:
            视频ID列表
        """
        video_ids = []
        found_videos = set()

        # RFC 3339 格式
        published_after = start_date.strftime('%Y-%m-%dT00:00:00Z')
        published_before = end_date.strftime('%Y-%m-%dT23:59:59Z')

        print(f"\n🔍 搜索视频 [{start_date.date()} ~ {end_date.date()}]")

        # 使用多种搜索策略
        search_strategies = [
            {'order': 'relevance', 'queries': self.GENERAL_QUERIES[:5]},
            {'order': 'viewCount', 'queries': self.GENERAL_QUERIES[5:10]},
            {'order': 'date', 'queries': self.GENERAL_QUERIES[10:]}
        ]

        for strategy in search_strategies:
            if len(video_ids) >= max_videos:
                break

            for query in strategy['queries']:
                if len(video_ids) >= max_videos:
                    break

                try:
                    search_params = {
                        'part': 'id,snippet',
                        'type': 'video',
                        'q': query,
                        'videoDuration': 'short',
                        'publishedAfter': published_after,
                        'publishedBefore': published_before,
                        'maxResults': min(50, max_videos - len(video_ids)),
                        'order': strategy['order'],
                        'regionCode': 'US'
                    }

                    request = self.youtube.search().list(**search_params)
                    response = request.execute()

                    for item in response.get('items', []):
                        if 'videoId' in item['id']:
                            video_id = item['id']['videoId']
                            if video_id not in found_videos:
                                found_videos.add(video_id)
                                video_ids.append(video_id)

                    time.sleep(1)  # API限流

                except Exception as e:
                    print(f"   ⚠ 搜索错误: {e}")
                    continue

        print(f"   ✓ 找到 {len(video_ids)} 个视频")
        self.stats['total_videos_searched'] += len(video_ids)
        return video_ids

    def collect_quarter(
        self,
        quarter_key: str,
        start_date: datetime,
        end_date: datetime,
        target_comments: int,
        comments_per_video: int = 30
    ) -> Tuple[List, Dict]:
        """
        采集单个季度的数据

        Args:
            quarter_key: 季度标识（如 2022Q1）
            start_date: 起始日期
            end_date: 结束日期
            target_comments: 目标评论数
            comments_per_video: 每视频评论数

        Returns:
            (comments, quarter_stats)
        """
        print("\n" + "="*80)
        print(f" 采集季度: {quarter_key}")
        print("="*80)
        print(f" 日期: {start_date.date()} ~ {end_date.date()}")
        print(f" 目标: {target_comments:,} 条评论")
        print("="*80)

        # 估算需要的视频数
        videos_needed = (target_comments // comments_per_video) * 2  # 多搜索备用

        # 搜索视频
        video_ids = self.search_videos_by_quarter(
            start_date, end_date, videos_needed
        )

        if not video_ids:
            print("❌ 未找到视频")
            return [], {}

        # 随机打乱（避免偏差）
        random.shuffle(video_ids)

        # 采集评论
        all_comments = []
        quarter_stats = {
            'quarter': quarter_key,
            'start_date': start_date.isoformat(),
            'end_date': end_date.isoformat(),
            'target_comments': target_comments,
            'collected_comments': 0,
            'videos_processed': 0,
            'ai_videos': 0,
            'non_ai_videos': 0,
            'ai_comments': 0,
            'non_ai_comments': 0,
            'detection_details': []
        }

        print(f"\n📝 开始采集评论...")

        for idx, video_id in enumerate(video_ids, 1):
            if len(all_comments) >= target_comments:
                print(f"\n✅ 已达到目标评论数 {target_comments:,}")
                break

            try:
                # 获取视频信息
                video_info = self.collector.get_video_info(video_id)

                # AI检测
                detection_result = self.detector.detect(video_info)

                video_type = 'ai_generated' if detection_result['is_ai'] else 'non_ai'

                # 更新统计
                if detection_result['is_ai']:
                    quarter_stats['ai_videos'] += 1
                    self.stats['ai_videos'] += 1
                else:
                    quarter_stats['non_ai_videos'] += 1
                    self.stats['non_ai_videos'] += 1

                # 获取评论
                comments = self.collector.get_video_comments(
                    video_id,
                    max_comments=min(comments_per_video, target_comments - len(all_comments)),
                    include_replies=True
                )

                # 为评论添加标签
                for comment in comments:
                    comment['quarter'] = quarter_key
                    comment['video_type'] = video_type
                    comment['ai_detection'] = detection_result

                all_comments.extend(comments)

                # 更新统计
                if detection_result['is_ai']:
                    quarter_stats['ai_comments'] += len(comments)
                else:
                    quarter_stats['non_ai_comments'] += len(comments)

                quarter_stats['videos_processed'] += 1

                # 记录检测详情
                quarter_stats['detection_details'].append({
                    'video_id': video_id,
                    'title': video_info['title'][:50],
                    'video_type': video_type,
                    'confidence': detection_result['confidence'],
                    'comments_collected': len(comments)
                })

                # 进度显示
                ai_ratio = quarter_stats['ai_comments'] / len(all_comments) * 100 if all_comments else 0
                print(f"  [{idx}/{len(video_ids)}] {video_id} | {video_type} "
                      f"(置信度:{detection_result['confidence']:.2f}) | "
                      f"{len(comments)}条评论 | 总计:{len(all_comments):,} | AI占比:{ai_ratio:.1f}%")

                time.sleep(0.5)

            except Exception as e:
                print(f"  ✗ 视频 {video_id} 失败: {e}")
                self.stats['detection_failures'] += 1
                continue

        quarter_stats['collected_comments'] = len(all_comments)
        self.stats['total_comments_collected'] += len(all_comments)
        self.stats['quarters_completed'] += 1

        # 计算季度AI占比
        ai_ratio = (quarter_stats['ai_comments'] / quarter_stats['collected_comments'] * 100
                   if quarter_stats['collected_comments'] > 0 else 0)

        print(f"\n✅ {quarter_key} 完成:")
        print(f"   评论总数: {quarter_stats['collected_comments']:,}")
        print(f"   AI内容: {quarter_stats['ai_comments']:,} ({ai_ratio:.1f}%)")
        print(f"   非AI: {quarter_stats['non_ai_comments']:,} ({100-ai_ratio:.1f}%)")
        print(f"   处理视频: {quarter_stats['videos_processed']}")

        return all_comments, quarter_stats

    def collect_all(
        self,
        start_date: str,
        end_date: str,
        total_comments: int,
        output_dir: Path
    ) -> Dict:
        """
        采集所有数据

        Args:
            start_date: 起始日期 (YYYY-MM-DD)
            end_date: 结束日期 (YYYY-MM-DD)
            total_comments: 目标总评论数
            output_dir: 输出目录

        Returns:
            采集结果统计
        """
        output_dir.mkdir(parents=True, exist_ok=True)

        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')

        # 生成季度列表
        quarters = self._generate_quarters(start_dt, end_dt)
        comments_per_quarter = total_comments // len(quarters)

        print("\n" + "="*80)
        print(" 自然分布采样 - 数据采集开始")
        print("="*80)
        print(f" 时间范围: {start_date} ~ {end_date}")
        print(f" 目标评论: {total_comments:,} 条")
        print(f" 季度数量: {len(quarters)}")
        print(f" 每季度: ~{comments_per_quarter:,} 条")
        print(" 策略: 不预设AI比例，让数据自然分布")
        print("="*80)

        all_comments = []
        all_quarter_stats = []

        for idx, quarter_info in enumerate(quarters, 1):
            print(f"\n进度: [{idx}/{len(quarters)}] 季度")

            try:
                comments, quarter_stats = self.collect_quarter(
                    quarter_info['key'],
                    quarter_info['start'],
                    quarter_info['end'],
                    comments_per_quarter,
                    comments_per_video=30
                )

                all_comments.extend(comments)
                all_quarter_stats.append(quarter_stats)

                # 保存季度检查点
                self._save_checkpoint(output_dir, comments, quarter_stats)

                # 显示累计进度
                self._print_cumulative_progress(all_quarter_stats, total_comments)

            except Exception as e:
                print(f"\n❌ 季度 {quarter_info['key']} 失败: {e}")
                continue

        # 保存最终结果
        final_result = self._save_final_results(
            output_dir, all_comments, all_quarter_stats
        )

        return final_result

    def _generate_quarters(self, start_date: datetime, end_date: datetime) -> List[Dict]:
        """生成季度列表"""
        quarters = []
        current = start_date

        while current <= end_date:
            year = current.year
            month = current.month
            quarter = (month - 1) // 3 + 1

            q_start = datetime(year, (quarter-1)*3 + 1, 1)
            if quarter < 4:
                q_end = datetime(year, quarter*3 + 1, 1) - timedelta(days=1)
            else:
                q_end = datetime(year, 12, 31)

            q_start = max(q_start, start_date)
            q_end = min(q_end, end_date)

            quarters.append({
                'key': f"{year}Q{quarter}",
                'start': q_start,
                'end': q_end
            })

            if quarter < 4:
                current = datetime(year, quarter*3 + 1, 1)
            else:
                current = datetime(year + 1, 1, 1)

        return quarters

    def _save_checkpoint(self, output_dir: Path, comments: List, quarter_stats: Dict):
        """保存季度检查点"""
        checkpoint_file = output_dir / f"checkpoint_{quarter_stats['quarter']}.json"
        with open(checkpoint_file, 'w', encoding='utf-8') as f:
            json.dump({
                'comments': comments,
                'stats': quarter_stats,
                'timestamp': datetime.now().isoformat()
            }, f, ensure_ascii=False, indent=2)

    def _print_cumulative_progress(self, all_stats: List[Dict], total_target: int):
        """打印累计进度"""
        total_collected = sum(s['collected_comments'] for s in all_stats)
        total_ai = sum(s['ai_comments'] for s in all_stats)
        total_non_ai = sum(s['non_ai_comments'] for s in all_stats)
        overall_ai_ratio = (total_ai / total_collected * 100) if total_collected > 0 else 0

        print(f"\n📊 累计进度:")
        print(f"   已采集: {total_collected:,} / {total_target:,} ({total_collected/total_target*100:.1f}%)")
        print(f"   AI内容: {total_ai:,} ({overall_ai_ratio:.1f}%)")
        print(f"   非AI: {total_non_ai:,} ({100-overall_ai_ratio:.1f}%)")
        print(f"   完成季度: {len(all_stats)}")

    def _save_final_results(
        self, output_dir: Path, comments: List, quarter_stats: List[Dict]
    ) -> Dict:
        """保存最终结果"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # 保存所有评论
        comments_file = output_dir / f'comments_natural_distribution_{timestamp}.json'
        with open(comments_file, 'w', encoding='utf-8') as f:
            json.dump(comments, f, ensure_ascii=False, indent=2)

        # 分离AI和非AI
        ai_comments = [c for c in comments if c.get('video_type') == 'ai_generated']
        non_ai_comments = [c for c in comments if c.get('video_type') == 'non_ai']

        ai_file = output_dir / f'comments_ai_{timestamp}.json'
        non_ai_file = output_dir / f'comments_non_ai_{timestamp}.json'

        with open(ai_file, 'w', encoding='utf-8') as f:
            json.dump(ai_comments, f, ensure_ascii=False, indent=2)
        with open(non_ai_file, 'w', encoding='utf-8') as f:
            json.dump(non_ai_comments, f, ensure_ascii=False, indent=2)

        # 保存元数据
        metadata = {
            'collection_timestamp': datetime.now().isoformat(),
            'total_comments': len(comments),
            'ai_comments': len(ai_comments),
            'non_ai_comments': len(non_ai_comments),
            'overall_ai_ratio': len(ai_comments) / len(comments) if comments else 0,
            'quarter_stats': quarter_stats,
            'collection_stats': self.stats,
            'files': {
                'all_comments': str(comments_file),
                'ai_comments': str(ai_file),
                'non_ai_comments': str(non_ai_file)
            }
        }

        metadata_file = output_dir / f'metadata_natural_distribution_{timestamp}.json'
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)

        # 打印最终报告
        self._print_final_report(metadata)

        return metadata

    def _print_final_report(self, metadata: Dict):
        """打印最终报告"""
        print("\n" + "="*80)
        print(" 🎉 数据采集完成！")
        print("="*80)

        print(f"\n📊 总体统计:")
        print(f"   总评论数: {metadata['total_comments']:,}")
        print(f"   AI内容: {metadata['ai_comments']:,} ({metadata['overall_ai_ratio']*100:.1f}%)")
        print(f"   非AI: {metadata['non_ai_comments']:,} ({(1-metadata['overall_ai_ratio'])*100:.1f}%)")

        print(f"\n📈 AI占比演变 (按季度):")
        print(f"   {'季度':<10} {'AI评论':<10} {'总评论':<10} {'AI占比':<10}")
        print(f"   {'-'*40}")
        for qstat in metadata['quarter_stats']:
            ai_ratio = (qstat['ai_comments'] / qstat['collected_comments'] * 100
                       if qstat['collected_comments'] > 0 else 0)
            print(f"   {qstat['quarter']:<10} {qstat['ai_comments']:<10} "
                  f"{qstat['collected_comments']:<10} {ai_ratio:<10.1f}%")

        print(f"\n💾 文件保存:")
        print(f"   全部评论: {metadata['files']['all_comments']}")
        print(f"   AI评论: {metadata['files']['ai_comments']}")
        print(f"   非AI评论: {metadata['files']['non_ai_comments']}")

        print(f"\n🔬 关键发现:")
        print(f"   • 总体AI占比: {metadata['overall_ai_ratio']*100:.1f}%")
        print(f"   • 这是真实世界分布，而非预设假设")
        print(f"   • AI占比的时间演变趋势可在分析中发现")

        print(f"\n✨ 下一步:")
        print(f"   1. 数据预处理: python scripts/preprocess_data.py")
        print(f"   2. AI占比趋势分析: python scripts/analyze_ai_ratio_evolution.py")
        print(f"   3. 情感分析: python scripts/run_sentiment_analysis.py")
        print(f"   4. 主题建模: python scripts/run_topic_modeling.py")
        print()


def main():
    parser = argparse.ArgumentParser(
        description='自然分布采样 - 不预设AI/非AI比例'
    )
    parser.add_argument('--total', type=int, default=100000,
                       help='目标总评论数 (默认 100,000)')
    parser.add_argument('--start-date', type=str, default='2022-01-01',
                       help='起始日期 YYYY-MM-DD')
    parser.add_argument('--end-date', type=str, default='2025-10-31',
                       help='结束日期 YYYY-MM-DD')
    parser.add_argument('--output-dir', type=str, default='data/raw',
                       help='输出目录')

    args = parser.parse_args()

    # 检查 API key
    api_key = os.getenv('YOUTUBE_API_KEY')
    if not api_key:
        print("\n❌ 错误：未找到 YouTube API 密钥")
        print("请设置环境变量: export YOUTUBE_API_KEY=your_key_here")
        return 1

    # 初始化采集器
    try:
        collector = NaturalDistributionCollector(api_key=api_key)
        print("\n✅ YouTube API 连接成功")
        print("✅ AI检测器已加载")
    except Exception as e:
        print(f"\n❌ 初始化失败: {e}")
        return 1

    # 开始采集
    try:
        result = collector.collect_all(
            start_date=args.start_date,
            end_date=args.end_date,
            total_comments=args.total,
            output_dir=Path(args.output_dir)
        )
        return 0
    except KeyboardInterrupt:
        print("\n\n⚠️ 用户中断")
        return 1
    except Exception as e:
        print(f"\n❌ 采集失败: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    sys.exit(main())
