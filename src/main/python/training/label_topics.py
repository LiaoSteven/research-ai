#!/usr/bin/env python3
"""
ä¸»é¢˜æ ‡ç­¾è„šæœ¬ - ç»™ä¸»é¢˜èµ‹äºˆæœ‰æ„ä¹‰çš„åç§°

æ ¹æ®å…³é”®è¯åˆ†æï¼Œç»™æ¯ä¸ªä¸»é¢˜IDèµ‹äºˆæè¿°æ€§åç§°

Usage:
    python scripts/label_topics.py \
        --input data/processed/comments_sentiment_topics.csv \
        --output data/processed/comments_labeled_topics.csv
"""

import sys
import argparse
from pathlib import Path
import pandas as pd
from collections import Counter
import json


# ä¸»é¢˜æ ‡ç­¾æ˜ å°„ï¼ˆæ ¹æ®å…³é”®è¯åˆ†æå¾—å‡ºï¼‰
TOPIC_LABELS = {
    0: {
        'name': 'Destiny Game Discussion',
        'name_zh': 'Destinyæ¸¸æˆè®¨è®º',
        'description': 'Comments about Destiny game, accounts, upgrades, and gameplay',
        'keywords': ['account', 'foltyn', 'destiny', 'upgrade', 'rising']
    },
    1: {
        'name': 'Gaming & Pokemon',
        'name_zh': 'æ¸¸æˆä¸å®å¯æ¢¦',
        'description': 'General gaming discussion, Pokemon, zombies mode',
        'keywords': ['pokemon', 'game', 'zombies', 'better', 'play']
    },
    2: {
        'name': 'Cazzu Music & Culture',
        'name_zh': 'CazzuéŸ³ä¹ä¸æ–‡åŒ–',
        'description': 'Comments about Cazzu (artist), music, Spanish content',
        'keywords': ['cazzu', 'music', 'hermosa', 'mujer', 'song']
    },
    3: {
        'name': 'Gaming Technical',
        'name_zh': 'æ¸¸æˆæŠ€æœ¯è®¨è®º',
        'description': 'Technical gaming discussion, timestamps, specific players',
        'keywords': ['josh', 'jandel', 'omega', 'owner', '11:34']
    },
    4: {
        'name': 'General Engagement',
        'name_zh': 'é€šç”¨äº’åŠ¨è®¨è®º',
        'description': 'Mixed general discussion with high engagement',
        'keywords': ['this', 'like', 'game', 'looks', 'people', 'good']
    }
}


def analyze_topic_keywords(df: pd.DataFrame, topic_id: int, top_n: int = 20) -> list:
    """
    åˆ†æä¸»é¢˜çš„å…³é”®è¯

    Args:
        df: æ•°æ®æ¡†
        topic_id: ä¸»é¢˜ID
        top_n: è¿”å›å‰Nä¸ªå…³é”®è¯

    Returns:
        å…³é”®è¯åˆ—è¡¨
    """
    topic_texts = df[df['topic'] == topic_id]['text'].tolist()

    # è¯é¢‘ç»Ÿè®¡
    all_words = []
    for text in topic_texts:
        words = str(text).lower().split()
        all_words.extend([w for w in words if len(w) > 3])

    word_freq = Counter(all_words).most_common(top_n)
    return [word for word, count in word_freq]


def label_topics(input_file: str, output_file: str):
    """
    ç»™ä¸»é¢˜æ·»åŠ æ ‡ç­¾

    Args:
        input_file: è¾“å…¥æ–‡ä»¶
        output_file: è¾“å‡ºæ–‡ä»¶
    """
    print(f"\nğŸ“Š è¯»å–æ•°æ®: {input_file}")
    df = pd.read_csv(input_file)

    print(f"  æ€»è¯„è®ºæ•°: {len(df)}")
    print(f"  æœ‰ä¸»é¢˜è¯„è®º: {len(df[df['topic'] >= 0])}")

    # æ·»åŠ ä¸»é¢˜æ ‡ç­¾åˆ—
    df['topic_name'] = df['topic'].map(lambda x: TOPIC_LABELS.get(x, {}).get('name', 'Unknown') if x >= 0 else 'No Topic')
    df['topic_name_zh'] = df['topic'].map(lambda x: TOPIC_LABELS.get(x, {}).get('name_zh', 'æœªçŸ¥') if x >= 0 else 'æ— ä¸»é¢˜')
    df['topic_description'] = df['topic'].map(lambda x: TOPIC_LABELS.get(x, {}).get('description', '') if x >= 0 else '')

    # ä¿å­˜
    print(f"\nğŸ’¾ ä¿å­˜åˆ°: {output_file}")
    df.to_csv(output_file, index=False)

    # æ‰“å°ç»Ÿè®¡
    print(f"\nğŸ“Š ä¸»é¢˜æ ‡ç­¾ç»Ÿè®¡:")
    topic_counts = df[df['topic'] >= 0].groupby(['topic', 'topic_name_zh']).size().reset_index(name='count')
    topic_counts['percentage'] = (topic_counts['count'] / topic_counts['count'].sum() * 100).round(1)

    for _, row in topic_counts.iterrows():
        print(f"  Topic {int(row['topic'])}: {row['topic_name_zh']}")
        print(f"    è¯„è®ºæ•°: {row['count']} ({row['percentage']}%)")
        print(f"    å…³é”®è¯: {', '.join(TOPIC_LABELS[int(row['topic'])]['keywords'][:5])}")
        print()

    return df


def generate_labeled_report(df: pd.DataFrame, output_dir: Path):
    """
    ç”Ÿæˆå¸¦æ ‡ç­¾çš„ä¸»é¢˜æŠ¥å‘Š

    Args:
        df: æ•°æ®æ¡†
        output_dir: è¾“å‡ºç›®å½•
    """
    print(f"\nğŸ“ ç”Ÿæˆå¸¦æ ‡ç­¾çš„ä¸»é¢˜æŠ¥å‘Š...")

    df_topics = df[df['topic'] >= 0].copy()

    report = []

    report.append("=" * 80)
    report.append("ä¸»é¢˜å»ºæ¨¡åˆ†ææŠ¥å‘Šï¼ˆå¸¦æ ‡ç­¾ï¼‰")
    report.append("YouTube Shorts Comments - Labeled Topic Analysis")
    report.append("=" * 80)
    report.append(f"\nç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report.append(f"åˆ†æè¯„è®ºæ•°: {len(df_topics):,}")
    report.append("")

    # ä¸»é¢˜åˆ†å¸ƒ
    report.append("=" * 80)
    report.append("ä¸»é¢˜åˆ†å¸ƒä¸è§£é‡Š")
    report.append("=" * 80)
    report.append("")

    for topic_id in sorted(df_topics['topic'].unique()):
        topic_df = df_topics[df_topics['topic'] == topic_id]
        topic_info = TOPIC_LABELS[topic_id]

        count = len(topic_df)
        pct = count / len(df_topics) * 100

        report.append(f"ä¸»é¢˜ {topic_id}: {topic_info['name_zh']} ({topic_info['name']})")
        report.append(f"{'='*80}")
        report.append(f"è¯„è®ºæ•°: {count:,} ({pct:.1f}%)")
        report.append(f"æè¿°: {topic_info['description']}")
        report.append(f"å…³é”®è¯: {', '.join(topic_info['keywords'])}")
        report.append("")

        # æƒ…æ„Ÿåˆ†å¸ƒ
        if 'sentiment' in topic_df.columns:
            sentiment_counts = topic_df['sentiment'].value_counts()
            report.append("æƒ…æ„Ÿåˆ†å¸ƒ:")
            for sent, sent_count in sentiment_counts.items():
                sent_pct = sent_count / count * 100
                report.append(f"  {sent}: {sent_count} ({sent_pct:.1f}%)")

        # äº’åŠ¨æ•°æ®
        if 'like_count' in topic_df.columns:
            report.append(f"\näº’åŠ¨æ•°æ®:")
            report.append(f"  å¹³å‡ç‚¹èµ: {topic_df['like_count'].mean():.2f}")
            report.append(f"  ä¸­ä½æ•°: {topic_df['like_count'].median():.0f}")
            report.append(f"  æœ€é«˜ç‚¹èµ: {topic_df['like_count'].max()}")

        # ç¤ºä¾‹è¯„è®ºï¼ˆæœ€é«˜ç‚¹èµï¼‰
        if 'text' in topic_df.columns and 'like_count' in topic_df.columns:
            top_comment = topic_df.nlargest(1, 'like_count').iloc[0]
            report.append(f"\næœ€å—æ¬¢è¿è¯„è®ºï¼ˆ{int(top_comment['like_count'])} èµï¼‰:")
            comment_text = str(top_comment['text'])[:150]
            if len(str(top_comment['text'])) > 150:
                comment_text += "..."
            report.append(f"  \"{comment_text}\"")

        report.append("")
        report.append("")

    # ä¸»é¢˜å¯¹æ¯”
    report.append("=" * 80)
    report.append("ä¸»é¢˜å¯¹æ¯”åˆ†æ")
    report.append("=" * 80)
    report.append("")

    # æœ€å—æ¬¢è¿ä¸»é¢˜
    if 'like_count' in df_topics.columns:
        avg_likes = df_topics.groupby(['topic', 'topic_name_zh'])['like_count'].mean().reset_index()
        avg_likes = avg_likes.sort_values('like_count', ascending=False)

        report.append("æœ€å—æ¬¢è¿ä¸»é¢˜ï¼ˆæŒ‰å¹³å‡ç‚¹èµï¼‰:")
        for _, row in avg_likes.iterrows():
            report.append(f"  {row['topic_name_zh']}: {row['like_count']:.2f} å¹³å‡ç‚¹èµ")
        report.append("")

    # æœ€ç§¯æä¸»é¢˜
    if 'sentiment' in df_topics.columns:
        positive_counts = df_topics[df_topics['sentiment'] == 'positive'].groupby(['topic', 'topic_name_zh']).size()
        total_counts = df_topics.groupby(['topic', 'topic_name_zh']).size()
        positive_ratio = (positive_counts / total_counts * 100).reset_index(name='positive_pct')
        positive_ratio = positive_ratio.sort_values('positive_pct', ascending=False)

        report.append("æœ€ç§¯æä¸»é¢˜ï¼ˆæŒ‰ç§¯ææƒ…æ„Ÿæ¯”ä¾‹ï¼‰:")
        for _, row in positive_ratio.iterrows():
            report.append(f"  {row['topic_name_zh']}: {row['positive_pct']:.1f}% ç§¯æ")
        report.append("")

    report.append("=" * 80)
    report.append("æŠ¥å‘Šç»“æŸ")
    report.append("=" * 80)

    # ä¿å­˜æŠ¥å‘Š
    report_text = '\n'.join(report)
    report_file = output_dir / 'topic_analysis_labeled_report.txt'

    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report_text)

    print(f"  âœ“ ä¿å­˜: {report_file}")

    return report_text


def main():
    parser = argparse.ArgumentParser(description='ä¸»é¢˜æ ‡ç­¾å·¥å…·')
    parser.add_argument('--input', required=True, help='è¾“å…¥ CSV æ–‡ä»¶')
    parser.add_argument('--output', required=True, help='è¾“å‡º CSV æ–‡ä»¶')

    args = parser.parse_args()

    print("=" * 80)
    print(" ä¸»é¢˜æ ‡ç­¾å·¥å…·")
    print("=" * 80)

    # æ·»åŠ æ ‡ç­¾
    df = label_topics(args.input, args.output)

    # ç”ŸæˆæŠ¥å‘Š
    output_dir = Path(args.output).parent.parent / 'output' / 'reports'
    output_dir.mkdir(parents=True, exist_ok=True)
    generate_labeled_report(df, output_dir)

    # ä¿å­˜ä¸»é¢˜æ ‡ç­¾é…ç½®
    config_file = output_dir / 'topic_labels_config.json'
    with open(config_file, 'w', encoding='utf-8') as f:
        json.dump(TOPIC_LABELS, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ä¸»é¢˜æ ‡ç­¾å®Œæˆï¼")
    print(f"\nğŸ“Š è¾“å‡ºæ–‡ä»¶:")
    print(f"  - å¸¦æ ‡ç­¾æ•°æ®: {args.output}")
    print(f"  - å¸¦æ ‡ç­¾æŠ¥å‘Š: {output_dir / 'topic_analysis_labeled_report.txt'}")
    print(f"  - æ ‡ç­¾é…ç½®: {config_file}")
    print()

    return 0


if __name__ == '__main__':
    sys.exit(main())
